{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b9f54b",
   "metadata": {},
   "source": [
    "Adapted from https://github.com/Specufex/specufex Specufex code\n",
    "\n",
    "Created Feb 1, 2023\n",
    "Updated Mar 13, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd4a71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from eqcorrscan import Tribe #reading tgz files with templates\n",
    "import obspy\n",
    "from obspy import Stream\n",
    "import csv #for reading and saving data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob #looking through files\n",
    "import scipy.signal as sp\n",
    "import yaml #for config file\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "from tqdm import trange\n",
    "from time import time #for time for code to run\n",
    "\n",
    "from specufex import BayesianNonparametricNMF, BayesianHMM #nmf and hmm functions\n",
    "from sklearn.cluster import KMeans #kmeans clustering function\n",
    "\n",
    "from matplotlib.gridspec import GridSpec #for plotting clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3ea980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baker\n"
     ]
    }
   ],
   "source": [
    "#set parameters\n",
    "with open('/home/smocz/expand_redpy/scripts/config.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "volc_list_names = config['volc_list_names']\n",
    "vv = config['vv']\n",
    "volc = volc_list_names[vv]\n",
    "print(volc)\n",
    "filename = f'Volcano_{volc}_Network_*_Station_*_Channel_*.tgz' #name of .tgz files to glob\n",
    "homedir = config['homedir']\n",
    "path = homedir+'templates/'\n",
    "\n",
    "winlen = config['winlen']\n",
    "\n",
    "fs = config['fs']\n",
    "fqmin = config['fqmin']\n",
    "fqmax = config['fqmax']\n",
    "\n",
    "# spectrogram parameters\n",
    "sgramMode='magnitude'\n",
    "sgramScaling='spectrum'\n",
    "\n",
    "# frequency/time resolution\n",
    "nperseg = config['nperseg'] \n",
    "noverlap = nperseg/config['dnoverlap']\n",
    "nfft = config['nfft']\n",
    "\n",
    "#Kmeans\n",
    "K=config['K'] # number of clusters to fit\n",
    "\n",
    "#NMF\n",
    "batches_nmf = config['batches_nmf']\n",
    "batch_size = config['batch_size']\n",
    "\n",
    "#HMM\n",
    "num_states = config['num_states']\n",
    "batches_hmm = config['batches_hmm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05866b2",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e529b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create window with max possible sum(abs(amplitudes))\n",
    "# goal is to align stream windows and provide shorter windows without as much noise\n",
    "def maxwindow(st,winlen): #provide stream object (one trace each) and window length in s\n",
    "    fs = st[0].stats.sampling_rate\n",
    "    stt = st[0].stats.starttime\n",
    "        \n",
    "    numwindows = round(len(st[0])/fs)-winlen+1 #how many windows will be cycled (+1 is for range)\n",
    "    print('number of windows:',numwindows-1)\n",
    "\n",
    "    sum_list = []\n",
    "    for i in range(0,numwindows):\n",
    "        tr = st[0].copy() #create copy to avoid trimming st[0]\n",
    "        tt = tr.trim(stt+i,stt+i+winlen) #trim to a window the length of winlen\n",
    "\n",
    "        amps_list = []\n",
    "        for ii in tt: #for each amplitude/point in the trace\n",
    "            amps_list.append(abs(ii)) #append the amplitude \n",
    "        sum_list.append(sum(amps_list)) #sum and save the amplitude for this possible window\n",
    "\n",
    "    max_inx = sum_list.index(max(sum_list)) #find the index of the window with maximum sum(abs(amplitudes))\n",
    "    \n",
    "    print('maximum amp window index:',max_inx) #print max_inx or the # second after beginning of template that \n",
    "    #the maximum window occurs\n",
    "    \n",
    "    final_tr = st[0].copy() #make a copy for trimming\n",
    "    \n",
    "    #adding 3s before to account for pwave/beginning of waveform\n",
    "    if max_inx-3 <= 0: #if 3s before max_inx is 0 or negative\n",
    "        inx = 0 #inx is 0\n",
    "    else: #if 3s before max_inx is >0\n",
    "        inx = max_inx-3 #inx is 3s before max_inx\n",
    "    \n",
    "    tr_trim = final_tr.trim(stt+max_inx,stt+max_inx+winlen) #use inx to trim the window corretly\n",
    "    print('Max Window:') #show the maximum window\n",
    "    tr_trim.plot();\n",
    "    \n",
    "    return(Stream(tr_trim)) #return the stream of the maximum window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d612b855",
   "metadata": {},
   "source": [
    "### Create spectrogram from templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ca72f",
   "metadata": {},
   "source": [
    "Create a dataframe of trimmed template waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame(data={'template_name':[],'waveform':[]}) #make a two column dataframe with labels\n",
    "\n",
    "for f_name in glob(f'{path}{filename}'): #loop thru tgz files at a volcano\n",
    "    T = Tribe().read(f_name)\n",
    "    \n",
    "    for t in T: #loop thru tgz file\n",
    "        print(f'{t.name} template original stream:') #show original stream\n",
    "\n",
    "        t.st.plot();\n",
    "\n",
    "        max_stream = maxwindow(st=t.st,winlen=winlen) #maxwindow func\n",
    "        \n",
    "        net = f_name.split('_')[6].lower() #f_name.split('_')[6].lower() is the network name\n",
    "\n",
    "        tdf.loc[len(tdf)+1] = [f'{net}.{t.name}',max_stream[0].data] #add this trimmed\n",
    "        #template to the df at index len+1\n",
    "        \n",
    "#         max_stream[0].spectrogram() #show spectrogram\n",
    "        print('---') #barrier\n",
    "\n",
    "#         break #only one template\n",
    "#     break #when break is on, only first station will be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9bc2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_spare = tdf.copy() #create a copy of the unaltered df for easier testing\n",
    "# tdf = tdf_spare #make tdf refer to this copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5804dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test tdf\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0ddd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see if trim length is not consistent - had some problems with trim at one point\n",
    "l_list = []\n",
    "for i in range(1,len(tdf['waveform'])):\n",
    "    l = len(tdf['waveform'][i]) #number of data points in a waveform\n",
    "    if l != (winlen*fs)+1: #if it is not 1601 (40fs times 40s plus 1)\n",
    "        print('inx',i,'l=',l) #show the index and number of data points\n",
    "        raise Exception('Some waveforms have not been properly trimmed') #raise an error if the trim lengths are not the same\n",
    "# print(np.unique(l_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ed3d8",
   "metadata": {},
   "source": [
    "Calculate spectrograms from trimmed template df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a94b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fSTFT, tSTFT, STFT_raw = sp.spectrogram(\n",
    "    x=np.stack(tdf[\"waveform\"].values),\n",
    "    fs=fs,\n",
    "    nperseg=nperseg,\n",
    "    noverlap=noverlap,\n",
    "    nfft=nfft,\n",
    "    scaling=sgramScaling,\n",
    "    axis=-1,\n",
    "    mode=sgramMode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quality check\n",
    "np.isnan(STFT_raw).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e925cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bandpass filter, optional\n",
    "freq_slice = np.where((fSTFT >= fqmin) & (fSTFT <= fqmax))\n",
    "fSTFT   = fSTFT[freq_slice]\n",
    "STFT_0 = STFT_raw[:,freq_slice,:].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normConstant = np.median(STFT_0, axis=(1,2))\n",
    "STFT_norm = STFT_0 / normConstant[:,np.newaxis,np.newaxis]  # norm by median\n",
    "del STFT_0\n",
    "STFT_dB = 20*np.log10(STFT_norm, where=STFT_norm != 0) # convert to dB\n",
    "del STFT_norm\n",
    "STFT = np.maximum(0, STFT_dB) # make sure nonnegative\n",
    "del STFT_dB\n",
    "\n",
    "tdf[\"stft\"] = list(STFT)\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quality check\n",
    "bad_idx = tdf[\"stft\"][tdf[\"stft\"].apply(lambda x: np.isnan(x).any())].index\n",
    "print(f\"Bad spectrograms: \\n{tdf.loc[bad_idx].template_name}\")\n",
    "tdf = tdf.drop(bad_idx).sort_values(\"template_name\")\n",
    "\n",
    "#this can mess with index sometimes (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting example spectrogram\n",
    "n_spectrogram = 0 # index of spectrogram to plot\n",
    "\n",
    "f, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "ax[0].pcolormesh(tSTFT,fSTFT,STFT_raw[n_spectrogram,freq_slice,:].squeeze())\n",
    "ax[0].set_xlabel(\"Timestep\")\n",
    "ax[0].set_ylabel(\"Frequency (Hz)\")\n",
    "ax[0].set_title(\"Original spectrogram\")\n",
    "\n",
    "ax[1].pcolormesh(tSTFT,fSTFT, STFT[n_spectrogram])\n",
    "ax[1].set_xlabel(\"Timestep\")\n",
    "ax[1].set_title(\"Normalized spectrogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save spectrogram df as a csv\n",
    "#tdf.to_csv(f'{homedir}{volc}_{winlen}s_window_spectrograms.csv',index=False)\n",
    "\n",
    "#right now this is kind of useless, it to_csv doesn't save the full waveform \n",
    "#or stft arrays, so they would have to be modified to be saved or saved in some other way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8624ee64",
   "metadata": {},
   "source": [
    "### Run Specufex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed028fbc",
   "metadata": {},
   "source": [
    "NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = BayesianNonparametricNMF(np.stack(tdf[\"stft\"].values).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef08e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = trange(batches_nmf, desc=\"NMF fit progress \", leave=True)\n",
    "for i in t:\n",
    "    idx = np.random.randint(len(tdf[\"stft\"].values), size=batch_size)\n",
    "    nmf.fit(tdf[\"stft\"].iloc[idx].values)\n",
    "    t.set_postfix_str(f\"Patterns: {nmf.num_pat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9dc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(nmf.EW@np.diag(nmf.EA[0]))\n",
    "plt.xlabel(\"NMF pattern number\")\n",
    "plt.xticks(range(0,nmf.num_pat,2), range(0,nmf.num_pat,2))\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c46ce",
   "metadata": {},
   "source": [
    "Activation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34473d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vs = nmf.transform(tdf[\"stft\"].values)\n",
    "# save Vs to an hdf5\n",
    "# with h5py.File(\"data/geysers/Vs.h5\", \"w\") as f:\n",
    "#     f[\"Vs\"] = Vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47970d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "axes[0].pcolormesh(Vs[0])\n",
    "axes[0].set_xlabel(\"Timestep\")\n",
    "axes[0].set_ylabel(\"NMF pattern\")\n",
    "# axes[0].set_yticks(range(0,nmf.num_pat,2), range(0,nmf.num_pat,2))\n",
    "# axes[0].set_title(\"Activation matrix\")\n",
    "\n",
    "# axes[1].pcolormesh(tdf[\"stft\"].iloc[0])\n",
    "# axes[1].set_xlabel(\"Timestep\")\n",
    "# axes[1].set_ylabel(\"Frequency\")\n",
    "# axes[1].set_title(\"Normalized spectrogram\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbffb1",
   "metadata": {},
   "source": [
    "HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e573b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = BayesianHMM(nmf.num_pat, nmf.gain, num_state=num_states, Neff=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bdd3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = trange(batches_hmm, desc=\"HMM fit progress \", leave=True)\n",
    "for i in t:\n",
    "    idx = np.random.randint(Vs.shape[0], size=1)\n",
    "    hmm.fit(Vs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f38377",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(hmm.EB, origin=\"lower\")\n",
    "plt.ylabel(\"HMM state\")\n",
    "plt.xlabel(\"Frequency pattern\")\n",
    "_=plt.yticks(range(0,num_states,5), range(0, num_states,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b14db",
   "metadata": {},
   "source": [
    "Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprints, As, gams = hmm.transform(Vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fingerprints[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73ff6a",
   "metadata": {},
   "source": [
    "### Cluster with Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert fingerprints from 2D array to 1D array\n",
    "fingerprints_ = fingerprints.reshape((fingerprints.shape[0], fingerprints.shape[1]**2))\n",
    "\n",
    "#Predicted labels\n",
    "y_pred = KMeans(n_clusters=K, random_state=42).fit_predict(fingerprints_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b13387d",
   "metadata": {},
   "source": [
    "### Saving the clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67567d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e369e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.unique(list(y_pred)): #list how many templates are in each kmeans cluster\n",
    "    print(\"Kmeans\",i,\"Count\",list(y_pred).count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tdf = tdf.copy() #create a copy of tdf for saving\n",
    "\n",
    "save_tdf['Kmeans'] = list(y_pred) #add Kmeans cluster to df\n",
    "test = save_tdf.drop(labels=[\"waveform\",\"stft\"],axis=1) #drop waveform and stft for saving\n",
    "test.reset_index(drop=True) #reset index (gets altered when editing df), drop=True removes old index\n",
    "\n",
    "#save to csv\n",
    "test.to_csv(f'/home/smocz/expand_redpy_new_files/kmeans_K_{K}_Volcano_{volc}.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ef4c5",
   "metadata": {},
   "source": [
    "### Reading csv and comparing clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c87fc",
   "metadata": {},
   "source": [
    "Vers for template name starpvo000 (instead of net.starpvo000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42afeab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(np.unique(tdf['Kmeans'].values.tolist()))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee0edc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "volc = \"Baker\" #can change volc name to look at specific volcano without reloading config.yaml\n",
    "filename = f'Volcano_{volc}_Network_*_Station_*_Channel_*.tgz' #name of .tgz files to glob\n",
    "\n",
    "fig = plt.figure(figsize=(30,40)) #make the figure and set the size\n",
    "gs = GridSpec(3, len(np.unique(tdf['Kmeans'].values.tolist()))+1, figure=fig) #set up gridspec\n",
    "\n",
    "tdf = pd.read_csv(f'/home/smocz/expand_redpy_new_files/kmeans_{volc}.csv') #read csv\n",
    "\n",
    "\n",
    "\n",
    "for K in np.unique(tdf['Kmeans'].values.tolist()): #for each kmeans cluster\n",
    "    print(f'Kmeans group {K} -------------------') #print which kmeans is being looked at\n",
    "    ax = fig.add_subplot(gs[:, K:K+1]) #create a subplot, place on gs\n",
    "    ax.set_title(f'Group {K}')\n",
    "    for nn,n in enumerate(tdf[tdf['Kmeans']==K]['template_name'].values.tolist()): #loop through template names in the df\n",
    "        time0 = time() #keep track of time\n",
    "        print(f'**finding stream for template {n}') #print which template is being looked at\n",
    "        for f_name in glob(f'{path}{filename}'): #loop thru tgz files at volcano            \n",
    "            if len(f_name.split('_')[8].lower()) == 3: #if sta name is 3 characters\n",
    "                if f_name.split('_')[8].lower() != n[:3]: #test against the first 3 characters of template name\n",
    "                    #change above n[:3] to n[3:6] for net.starpvo000 instead of starpvo000\n",
    "                    continue #go to next possible file if the station is wrong\n",
    "\n",
    "            if len(f_name.split('_')[8].lower()) == 4: #if sta name is 4 characters\n",
    "                if f_name.split('_')[8].lower() != n[:4]: #test against the first 4 characters of template name\n",
    "                    #change above n[:4] to n[3:7] for net.starpvo000 instead of starpvo000\n",
    "                    continue #go to next possible file if the station is wrong\n",
    "\n",
    "\n",
    "            T = Tribe().read(f_name) #read tgz file\n",
    "\n",
    "            for t in T: #for each template in tgz file\n",
    "                if t.name == n: #if the template name matches the template we want\n",
    "                    #change above n to n[3:] for net.starpvo000 instead of starpvo000\n",
    "                    st = t.st #grab the stream\n",
    "                    \n",
    "                    ax.plot(st[0].data[:]/np.max(np.abs(st[0].data))+2*nn)\n",
    "#                     st.plot(); #plot stream\n",
    "        \n",
    "        time1 = time() #keep track of time\n",
    "        print(f'{time1-time0}s to search for stream') #find time to go through this loop\n",
    "#         break #will only go through one template\n",
    "#     break #will only go through one kmeans group\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ff6e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans 0 Count 244\n",
      "Kmeans 1 Count 65\n",
      "Kmeans 2 Count 74\n",
      "Kmeans 3 Count 125\n"
     ]
    }
   ],
   "source": [
    "for i in np.unique(tdf['Kmeans'].values.tolist()): #list how many templates are in each kmeans cluster\n",
    "    print(\"Kmeans\",i,\"Count\",tdf['Kmeans'].values.tolist().count(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40682d69",
   "metadata": {},
   "source": [
    "Vers for template name net.starpvo000 (instead of starpvo000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5dd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "volc = \"Baker\" #can change volc name to look at specific volcano without reloading config.yaml\n",
    "filename = f'Volcano_{volc}_Network_*_Station_*_Channel_*.tgz' #name of .tgz files to glob\n",
    "\n",
    "\n",
    "tdf = pd.read_csv(f'/home/smocz/expand_redpy_new_files/kmeans_{volc}.csv') #read csv\n",
    "\n",
    "for K in np.unique(tdf['Kmeans'].values.tolist()): #for each kmeans cluster\n",
    "    print(f'Kmeans group {K} -------------------') #print which kmeans is being looked at\n",
    "    for n in tdf[tdf['Kmeans']==K]['template_name'].values.tolist(): #loop through template names in the df\n",
    "        time0 = time() #keep track of time\n",
    "        print(f'**finding stream for template {n}') #print which template is being looked at\n",
    "        for f_name in glob(f'{path}{filename}'): #loop thru tgz files at volcano            \n",
    "            if len(f_name.split('_')[8].lower()) == 3: #if sta name is 3 characters\n",
    "                if f_name.split('_')[8].lower() != n[3:6]: #test against the first 3 characters of template name\n",
    "                    continue #go to next possible file if the station is wrong\n",
    "\n",
    "            if len(f_name.split('_')[8].lower()) == 4: #if sta name is 4 characters\n",
    "                if f_name.split('_')[8].lower() != n[3:7]: #test against the first 4 characters of template name\n",
    "                    continue #go to next possible file if the station is wrong\n",
    "\n",
    "\n",
    "            T = Tribe().read(f_name) #read tgz file\n",
    "\n",
    "            for t in T: #for each template in tgz file\n",
    "                if t.name == n[3:]: #if the template name matches the template we want\n",
    "                    st = t.st #grab the stream\n",
    "                    st.plot(); #plot stream\n",
    "        \n",
    "        time1 = time() #keep track of time\n",
    "        print(f'{time1-time0}s to search for stream') #find time to go through this loop\n",
    "        break #will only go through one template\n",
    "    break #will only go through one kmeans group\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e28ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo-py38-shared"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

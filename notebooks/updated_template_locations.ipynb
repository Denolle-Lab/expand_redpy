{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348ac66f",
   "metadata": {},
   "source": [
    "Created August 17, 2023\n",
    "\n",
    "Purpose is to update location grid search in the following ways:\n",
    "1. use templates whose constituent waveforms were normalized before stacking (fixes most false features)\n",
    "2. use elep to find picktimes instead of envelope cross correlation\n",
    "3. base velocity model of grid search on p and s picktimes when possible\n",
    "4. compare locations to ComCat potential matches from the <a href=\"https://assets.pnsn.org/red/\">redpy website</a> when possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5425951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched-filter CPU is not compiled! Should be here: /home/jupyter_share/miniconda3/envs/seismo/lib/python3.8/site-packages/fast_matched_filter/lib/matched_filter_CPU.so\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import h5py\n",
    "import yaml\n",
    "import csv\n",
    "import eqcorrscan\n",
    "from eqcorrscan import Tribe\n",
    "from time import time\n",
    "import obspy\n",
    "from obspy import UTCDateTime, Trace\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from obspy.signal.cross_correlation import *\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy import distance\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "# from utils import *\n",
    "\n",
    "\n",
    "import seisbench.models as sbm\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "from ELEP.elep.ensemble_statistics import ensemble_statistics\n",
    "from ELEP.elep.ensemble_coherence import ensemble_semblance \n",
    "from ELEP.elep.ensemble_learners import ensemble_regressor_cnn\n",
    "from mbf_elep_func import apply_mbf\n",
    "from ELEP.elep import mbf, mbf_utils\n",
    "from ELEP.elep import trigger_func\n",
    "from ELEP.elep.trigger_func import picks_summary_simple\n",
    "\n",
    "from ELEP.elep.mbf_utils import make_LogFq, make_LinFq, rec_filter_coeff, create_obspy_trace\n",
    "from ELEP.elep.mbf import MB_filter as MBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a076193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hood\n"
     ]
    }
   ],
   "source": [
    "#read config file for parameters\n",
    "with open('/home/smocz/expand_redpy/scripts/config.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "smooth_length = config['smooth_length']\n",
    "fs = config['fs']\n",
    "tb = config['tb']\n",
    "ta = config['ta']\n",
    "fqmin = config['fqmin']\n",
    "fqmax = config['fqmax']\n",
    "chan = config['chan']\n",
    "homedir = config['homedir']\n",
    "readdir = config['readdir']\n",
    "minsta = config['minsta']\n",
    "grid_length = float(config['grid_length'])\n",
    "grid_height = float(config['grid_height'])\n",
    "step = config['step']\n",
    "t_step = config['t_step']\n",
    "vs_min = config['vs_min']\n",
    "vs_max = config['vs_max']\n",
    "vs_step = config['vs_step']\n",
    "volc_lat_lon = config['volc_lat_lon']\n",
    "volc_list_names = config['volc_list_names']\n",
    "\n",
    "vv = config['vv']\n",
    "\n",
    "\n",
    "print(volc_list_names[vv])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3fda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "volc_md = pd.read_csv(readdir+'Volcano_Metadata.csv')\n",
    "#associate network and station\n",
    "volc_md['netsta'] = volc_md['Network'].astype(str)+'.'+volc_md['Station'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9b8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#color map for plotting\n",
    "def get_cmap(n, name='viridis'): #hsv\n",
    "#     Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "#     RGB color; the keyword argument name must be a standard mpl colormap name.\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "# define function to predict synthetic arrival times\n",
    "def travel_time(t0, x, y, vs, sta_x, sta_y):\n",
    "    dist = np.sqrt((sta_x - x)**2 + (sta_y - y)**2)\n",
    "    tt = t0 + dist/vs\n",
    "    return tt\n",
    "\n",
    "# define function to compute residual sum of squares\n",
    "def error(synth_arrivals,arrivals):\n",
    "    res = arrivals - synth_arrivals   #make sure arrivals are in the right order, maybe iterate through keys\n",
    "    res_sqr = res**2\n",
    "    rss = np.sum(res_sqr)\n",
    "    return rss\n",
    "\n",
    "# define function to iterate through grid and calculate travel time residuals\n",
    "def gridsearch(t0,x_vect,y_vect,sta_x,sta_y,vs,arrivals):\n",
    "    rss_mat = np.zeros((len(t0),len(x_vect),len(y_vect)))\n",
    "    rss_mat[:,:,:] = np.nan\n",
    "    for i in range(len(t0)): \n",
    "        for j in range(len(x_vect)):\n",
    "            for k in range(len(y_vect)):\n",
    "                for m in range(len(vs)): #parameterize velocity\n",
    "                    synth_arrivals = []\n",
    "                    for h in range(len(sta_x)):\n",
    "                        tt = travel_time(t0[i],x_vect[j],y_vect[k],vs[m],sta_x[h],sta_y[h]) \n",
    "                    #add vs in nested loop, vector 1000-5000, per cluster to account for p and s waves\n",
    "                        synth_arrivals.append(tt)\n",
    "                    rss = error(np.array(synth_arrivals),np.array(arrivals))\n",
    "                    rss_mat[i,j,k] = rss\n",
    "    return rss_mat\n",
    "\n",
    "# define function to convert the location index into latitude and longitude\n",
    "def location(x_dist, y_dist, start_lat, start_lon):\n",
    "    bearing = 90-np.rad2deg(np.arctan(y_dist/x_dist))\n",
    "    dist = np.sqrt((x_dist)**2 + (y_dist)**2)\n",
    "    d = distance.geodesic(meters = dist)\n",
    "    loc_lat = d.destination(point=[start_lat,start_lon], bearing=bearing)[0]\n",
    "    loc_lon = d.destination(point=[start_lat,start_lon], bearing=bearing)[1]\n",
    "    return loc_lat, loc_lon, d\n",
    "\n",
    "# define function to find diameter in meters of the error on the location\n",
    "def error_diameter(new_array):\n",
    "    min_idx = np.min(new_array[:,1])\n",
    "    max_idx = np.max(new_array[:,1])\n",
    "    difference = max_idx-min_idx\n",
    "    diameter_m = difference*1000\n",
    "    return diameter_m \n",
    "\n",
    "#get clusterid from template name\n",
    "def getcl_id(t_name_str): #for normalized\n",
    "    t_cl = int(t_name_str.split('_')[-1])\n",
    "    return t_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81685e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML picker parameters\n",
    "paras_semblance = {'dt':0.025, 'semblance_order':4, 'window_flag':True, \n",
    "                   'semblance_win':0.5, 'weight_flag':'max'}\n",
    "p_thrd, s_thrd = 0.01, 0.05\n",
    "\n",
    "# download models\n",
    "pretrain_list = [\"pnw\",\"ethz\",\"instance\",\"scedc\",\"stead\",\"geofon\",\"neic\"]\n",
    "pn_pnw_model = sbm.EQTransformer.from_pretrained('pnw')\n",
    "pn_ethz_model = sbm.EQTransformer.from_pretrained(\"ethz\")\n",
    "pn_instance_model = sbm.EQTransformer.from_pretrained(\"instance\")\n",
    "pn_scedc_model = sbm.EQTransformer.from_pretrained(\"scedc\")\n",
    "pn_stead_model = sbm.EQTransformer.from_pretrained(\"stead\")\n",
    "pn_geofon_model = sbm.EQTransformer.from_pretrained(\"geofon\")\n",
    "pn_neic_model = sbm.EQTransformer.from_pretrained(\"neic\")\n",
    "\n",
    "#list of models to run through\n",
    "list_models = [pn_pnw_model,pn_ethz_model,pn_scedc_model,pn_neic_model,pn_geofon_model,pn_stead_model,pn_instance_model]\n",
    "\n",
    "pn_pnw_model.to(device); #imodel 0\n",
    "pn_ethz_model.to(device); #imodel 1\n",
    "pn_scedc_model.to(device); #imodel 2\n",
    "pn_neic_model.to(device); #imodel 3\n",
    "pn_geofon_model.to(device); #imodel 4\n",
    "pn_stead_model.to(device); #imodel 5\n",
    "pn_instance_model.to(device); #imodel 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774096b3",
   "metadata": {},
   "source": [
    "Find picktimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c46c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in h5 for volcano\n",
    "\n",
    "all_temps = []\n",
    "all_waves = []\n",
    "\n",
    "for filepath in glob(f'/home/smocz/expand_redpy_new_files/h5/normalized_{volc_list_names[vv].lower()}_templates_*.h5'):\n",
    "    net = filepath.split('_')[-2]\n",
    "    with h5py.File(filepath, \"r\") as f: #pull in fingerprints\n",
    "        template_name = f[\"template_name\"][()]\n",
    "        waveforms = f[\"waveforms\"][()]\n",
    "#         print(f.keys()) #print what data is in this file\n",
    "    [all_temps.append(i) for i in template_name]\n",
    "    [all_waves.append(i) for i in waveforms]\n",
    "    \n",
    "all_waves = np.array(all_waves)\n",
    "all_temps = [str(i)[2:-1] for i in all_temps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9180d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some info\n",
    "v = volc_md[volc_md['Volcano_Name'] == volc_list_names[vv]]['netsta'].values.tolist() #list of network and station per volc\n",
    "clid = np.unique([getcl_id(i) for i in all_temps]) #list of cluster ids\n",
    "cllen = len(str(max(clid))) #length of the largest cluster ID, used for zfill\n",
    "zz = chan[-2:].lower() #the last two letters of channel names (essentially the letters in chan)\n",
    "csv_name = f'{homedir}locations/{volc_list_names[vv]}_ELEP_normalized_picktimes.csv' #name of the csv for picktimes at this volcano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24567ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create csv for volcano\n",
    "with open(csv_name, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Network','Station','Cluster_ID','Template_Name','SMB_peak','SMB_peak_MBF'])\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b37d1b3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding picktimes for each cluster:   0%|          | 0/169 [00:00<?, ?it/s]\n",
      "Finding picktimes for each station at cluster 0:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Finding picktimes for each station at cluster 0:  62%|██████▎   | 10/16 [01:12<00:43,  7.27s/it]\u001b[A\n",
      "Finding picktimes for each station at cluster 0:  69%|██████▉   | 11/16 [02:25<01:17, 15.44s/it]\u001b[A\n",
      "Finding picktimes for each station at cluster 0:  81%|████████▏ | 13/16 [03:38<01:02, 20.94s/it]\u001b[A\n",
      "Finding picktimes for each station at cluster 0: 100%|██████████| 16/16 [04:50<00:00, 18.17s/it]\u001b[A\n",
      "Finding picktimes for each cluster:   1%|          | 1/169 [04:50<13:34:00, 290.71s/it]\n",
      "Finding picktimes for each station at cluster 1:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Finding picktimes for each station at cluster 1:  12%|█▎        | 2/16 [01:12<08:29, 36.40s/it]\u001b[A\n",
      "Finding picktimes for each station at cluster 1:  56%|█████▋    | 9/16 [02:32<01:58, 16.90s/it]\u001b[A\n",
      "Finding picktimes for each cluster:   1%|          | 1/169 [07:22<20:39:46, 442.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m paras_semblance \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m:dt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemblance_order\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow_flag\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     54\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemblance_win\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_flag\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#find picktimes!\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m smb_peak,smb_peak_mbf \u001b[38;5;241m=\u001b[39m \u001b[43mapply_mbf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevt_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msta_available\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43mlist_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMBF_paras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparas_semblance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#append picks to csv\u001b[39;00m\n\u001b[1;32m     61\u001b[0m row \u001b[38;5;241m=\u001b[39m [net, sta, cl, t, smb_peak[\u001b[38;5;241m0\u001b[39m], smb_peak_mbf[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m~/expand_redpy/notebooks/mbf_elep_func.py:71\u001b[0m, in \u001b[0;36mapply_mbf\u001b[0;34m(evt_data, list_sta, list_models, MBF_paras, paras_semblance, t_before, t_around, thr)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# batch predict picks.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ii, imodel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(list_models):\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#         print('imodel',ii)\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m         batch_pred[ii, :, :] \u001b[38;5;241m=\u001b[39m \u001b[43mimodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_tt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[:, :]\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#         print('batch prediction!')\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m############# Multi-band Workflow ########\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     windows_std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m(nsta, MBF_paras[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnfqs\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m3\u001b[39m, twin), dtype\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.8/site-packages/seisbench/models/eqtransformer.py:267\u001b[0m, in \u001b[0;36mEQTransformer.forward\u001b[0;34m(self, x, logits)\u001b[0m\n\u001b[1;32m    263\u001b[0m px \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(px)\n\u001b[1;32m    264\u001b[0m px \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mpermute(\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    266\u001b[0m )  \u001b[38;5;66;03m# From sequence, batch, channels to batch, channels, sequence\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m px, _ \u001b[38;5;241m=\u001b[39m \u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m px \u001b[38;5;241m=\u001b[39m decoder(px)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits:\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/jupyter_share/miniconda3/envs/seismo/lib/python3.8/site-packages/seisbench/models/eqtransformer.py:650\u001b[0m, in \u001b[0;36mSeqSelfAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    643\u001b[0m q \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(\n\u001b[1;32m    644\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmatmul(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWt), \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    645\u001b[0m )  \u001b[38;5;66;03m# Shape (batch, time, 1, channels)\u001b[39;00m\n\u001b[1;32m    646\u001b[0m k \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(\n\u001b[1;32m    647\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmatmul(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWx), \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    648\u001b[0m )  \u001b[38;5;66;03m# Shape (batch, 1, time, channels)\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbh\u001b[49m)\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# Emissions\u001b[39;00m\n\u001b[1;32m    653\u001b[0m e \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(\n\u001b[1;32m    654\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmatmul(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWa) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mba, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    655\u001b[0m )  \u001b[38;5;66;03m# Shape (batch, time, time)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### PULL IN TEMPLATES ###\n",
    "cl_trange = trange(max(clid), desc=\"Finding picktimes for each cluster\", leave=True)\n",
    "for cl in cl_trange:\n",
    "#     print('------') #print a divider\n",
    "#     print(\"cluster:\",str(cl).zfill(cllen)) #print the cluster ID\n",
    "    \n",
    "    temps_w = [] #list of templates waveforms for this cluster\n",
    "    temps_n = [] #list of template names\n",
    "    temps_p = [] #list of template picks (list of arrays)\n",
    "    \n",
    "    stopwatch0=time() #note the time\n",
    "    \n",
    "    s_trange = trange(len(v), desc=f\"Finding picktimes for each station at cluster {cl}\", leave=True)\n",
    "    for s in s_trange: #loop through stations that have a template for this cluster\n",
    "        net, sta =  v[s].split('.') #add specific network per station\n",
    "        \n",
    "        for tt,t in enumerate(all_temps): #go through each template\n",
    "            if t.split('_')[0]==net and t.split('_')[1]==sta and t.split('_')[-1]==str(cl): #if the template is for this station and cluster\n",
    "                \n",
    "                ### PREPARE DATA ###\n",
    "#                 Trace(all_waves[tt]).plot(); #show before preparation\n",
    "                wave = all_waves[tt].copy() #create copy\n",
    "                \n",
    "                t_tapered = Trace(wave).taper(0.05) #make waveform a trace to taper it\n",
    "                padded_wave = np.hstack((t_tapered.data[:],np.zeros(2480))) #take data from tapered trace and pad end \n",
    "                #with zeros so that len(t_trace)=6000 and will fit in the nueral network\n",
    "                t_trace = Trace(padded_wave,{'sampling_rate':fs}) #make back into a Trace, and set sampling rate\n",
    "#                 print(len(t_trace))\n",
    "                \n",
    "                temps_w.append(t_trace) #append trace\n",
    "                temps_n.append(t) #append name\n",
    "                \n",
    "#                 t_trace.plot(); #plot trace after preparation\n",
    "\n",
    "    \n",
    "                ### FIND PICKS! ###\n",
    "\n",
    "                #picking params\n",
    "                evt_data = Stream(traces=[t_trace])\n",
    "                sta_available = [sta]\n",
    "                list_models = list_models\n",
    "                twin = len(t_trace)-1\n",
    "\n",
    "\n",
    "                dt = 1/fs; fs = fs\n",
    "                nfqs = 5\n",
    "                nt = 6000; nc = 3\n",
    "                fq_list = make_LogFq(fqmin, fqmax, dt, nfqs)\n",
    "                coeff_HP, coeff_LP = rec_filter_coeff(fq_list, dt)\n",
    "                MBF_paras = {'f_min':fqmin, 'f_max':fqmax, 'nfqs':nfqs, 'frequencies':fq_list, 'CN_HP':coeff_HP, 'CN_LP':coeff_LP, \\\n",
    "                    'dt':dt, 'fs':fs, 'nt':nt, 'nc':nc, 'npoles': 2}\n",
    "\n",
    "                paras_semblance = {'dt':dt, 'semblance_order':2, 'window_flag':True, \n",
    "                                   'semblance_win':0.5, 'weight_flag':'max'}\n",
    "                \n",
    "                #find picktimes!\n",
    "                smb_peak,smb_peak_mbf = apply_mbf(evt_data, sta_available, \\\n",
    "                list_models, MBF_paras, paras_semblance)\n",
    "        \n",
    "                #append picks to csv\n",
    "                row = [net, sta, cl, t, smb_peak[0], smb_peak_mbf[0]]\n",
    "                with open(csv_name, 'a', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(row)\n",
    "                    file.close()\n",
    "                \n",
    "    \n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smb_peak,smb_peak_mbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c030ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_trace.data[:6000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380b507",
   "metadata": {},
   "source": [
    "### Plotting times as vlines on templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc359a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in csv with picktimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587bd02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to plot each template, and each picktime as a vline\n",
    "#one plot per redpy cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784fead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81bfb2eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2fb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "array0 = np.array([0,0,0,3,4,5,6])\n",
    "array1 = np.zeros(6)\n",
    "print(np.hstack((array0,array1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f78b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Trace(all_waves[tt],{'sampling_rate':40}))/40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b5254",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = volc_sta[vv] \n",
    "clid = np.unique([getcl_id(i) for i in all_temps]) #list of cluster ids\n",
    "cllen = len(max(clid)) #length of the largest cluster ID, used for zfill\n",
    "zz = chan[-2:].lower() #the last two letters of channel names (essentially the letters in chan)\n",
    "#make csv?\n",
    "\n",
    "\n",
    "\n",
    "for cl in range(0,max(clid)):#options: cl in range(0,clid[-1]+1) for specific ranges; cl in clid for all Cluster IDs\n",
    "    temps_s = {} #empty dictionary that will be filled with the templates for this cluster\n",
    "    print('------') #print a divider\n",
    "    print(\"cluster:\",str(cl).zfill(cllen)) #print the cluster ID\n",
    "    stopwatch0=time() #note the time\n",
    "    for s in range(0,len(v)): #loop through stations\n",
    "        net, sta =  v[s].split('.') #add specific network per station\n",
    "\n",
    "########################################################################    \n",
    "#                       FINDING PICK TIMES                             #\n",
    "########################################################################\n",
    "\n",
    "        # try to read the h5 file\n",
    "        try:\n",
    "            T = Tribe().read(*glob(f'{homedir}templates/Volcano_{volc_list_names[vv]}_Network_{net}_Station_{sta}_Channel_*.tgz'))\n",
    "        except:\n",
    "            print(f'{net}.{sta} tgz does not exist')\n",
    "            continue\n",
    "        for t in T: #for each template in the tgz\n",
    "            if t.name.endswith(str(cl).zfill(cllen)): #if the template name endswith this cluster\n",
    "                temps_s[f'{net.lower()}.{t.name}']=t #save to dictionary and include network name\n",
    "                break\n",
    "\n",
    "    if len(temps_s) < minsta: #if the number of templates for this cluster is less than minsta (see config)\n",
    "        print('not enough stations with data for this cluster') #print a reminder\n",
    "        stopwatch2=time() #note the time\n",
    "        print(f'{stopwatch2-stopwatch0} s for this cluster') #say how many s to go through this cluster\n",
    "        continue #move onto the next cluster\n",
    "        \n",
    "    data_env_dict = {} #a dictionary of the envelopes for each template stream\n",
    "    for t in temps_s: #for each saved template (aka each template for this cluster and volc that exists)\n",
    "        data_envelope = obspy.signal.filter.envelope(temps_s[t].st[0].data) #make an envelope\n",
    "        data_envelope /= np.max(data_envelope) #average envelope (?)\n",
    "        data_envelope = obspy.signal.util.smooth(data_envelope, smooth_length) #smooth the envelope\n",
    "        data_env_dict[t] = data_envelope #save the envelope to the dictionary\n",
    "\n",
    "    pick_times = {} #dictionary of picktimes for each template\n",
    "    for key in data_env_dict: #for each envelope\n",
    "        p, shift, relative_p = pick_time(ref_env=data_env_dict[list(data_env_dict.keys())[0]], \n",
    "                data_env_dict=data_env_dict[key],st=temps_s[key].st) #calculate picktimes\n",
    "        pick_times[key] = relative_p #save to dictionary\n",
    "    print(f'{cl} offsets are {pick_times}') #print pick times relative to first template stream (can be negative)\n",
    "    \n",
    "    #arranging picktimes from 0 (earliest station) to later (positive) times\n",
    "    #will NOT be used for plotting picktimes, but will be used for location\n",
    "    dif_dict = {} #dictionary of picktimes in reference to earliest picktime (in positive seconds after the earliest picktime)\n",
    "    max_value = max(pick_times, key=pick_times.get) #get key for max value of pick_times aka the earliest picktime\n",
    "    for key in pick_times: #for each picktime\n",
    "        dif = round(abs(pick_times[max_value] - pick_times[key]),4) #max value minus current value\n",
    "        dif_dict[key] = dif #save to dictionary with the same key as pick_times\n",
    "\n",
    "    \n",
    "########################################################################    \n",
    "#                       PLOTTING PICK TIMES                            #\n",
    "########################################################################\n",
    "\n",
    "#     cmap = get_cmap(len(temps_s)) #get cmap aka colors for the plot, see def(get_cmap) for color palette\n",
    "#     plt.figure(figsize=(10,10)) #set plot size\n",
    "#     plt.title('aligned templates, vlines are template starts') #plot title\n",
    "#     for tt,t in enumerate(temps_s): #for every template\n",
    "#         shift = round(pick_times[t]*fs) #find shift based on picktimes\n",
    "#         st0 = temps_s[t].st.copy() #make a copy for a reference\n",
    "#         maxdata = len(temps_s[t].st[0].data[:]) #find maximum length of template stream\n",
    "\n",
    "#         empty = Trace(np.zeros(shift)) #an empty trace/a trace filled with zeros\n",
    "#         if shift<0: #if shift is negative\n",
    "#             temps_s[t].st[0].data[:shift]=st0[0].data[-shift:] #shift to the left\n",
    "#         if shift>0: #if shift is positive\n",
    "#             temps_s[t].st[0].data[shift:]=st0[0].data[:-shift] #shift to the right\n",
    "#             temps_s[t].st[0].data[:shift]=empty.data[:shift] #get rid of leftover data from shift\n",
    "#         #note: if shift == 0, will be plotting with no shifting\n",
    "#         plt.plot(temps_s[t].st[0].data[:]/np.max(np.abs(temps_s[t].st[0].data[:]))+2*tt,color=cmap(tt), label=t) #plot stream\n",
    "#         plt.vlines(shift,ymin=-1,ymax=2*len(temps_s),color=cmap(tt)) #plot line in same color representing the start of the template\n",
    "#         plt.legend() #show the legend\n",
    "    \n",
    "#     first_sta = max(pick_times, key=pick_times.get) #gives you the template name for the first\n",
    "    #station to get a signal (largest/most positive pick time)\n",
    "    \n",
    "########################################################################    \n",
    "#                         FINDING LOCATION                             #\n",
    "########################################################################\n",
    "\n",
    "    # define input parameters\n",
    "    arrivals = [] #relative picktimes, dif_dict as a list\n",
    "    sta_lats = [] #station latitudes, from metadata\n",
    "    sta_lons = [] #station longitudes, from metadata\n",
    "    netsta_names = [] #list of station names with networks\n",
    "    for key in dif_dict: #for each station\n",
    "        arrivals.append(dif_dict[key]) #append pick time to arrivals\n",
    "        \n",
    "        #finding station name\n",
    "        if not key.endswith(str(cl).zfill(cllen)): #if the wrong cluster id\n",
    "            print('template name does not match cluster ID') #print an error\n",
    "            continue #and skip the rest\n",
    "        if key.endswith(f'{zz}rp{volc_list_names[vv][:2].lower()}{str(cl).zfill(cllen)}'): #if the key has a channel name in it (the 'hz')\n",
    "            md_netsta = key[:-(7+cllen)] #remember the stuff before channel name rpvo and cluster ID\n",
    "        if not key.endswith(f'{zz}rp{volc_list_names[vv][:2].lower()}{str(cl).zfill(cllen)}'): #if the key has NO channel name in it\n",
    "            md_netsta = key[:-(4+cllen)] #remember the stuff before rpvo and cluster ID\n",
    "#         print(md_netsta)\n",
    "        lat = volc_md[volc_md['netsta']==md_netsta.upper()]['Latitude'].values.tolist() #get latitude from metadata\n",
    "        sta_lats.append(lat[0]) #append\n",
    "        \n",
    "        lon = volc_md[volc_md['netsta']==md_netsta.upper()]['Longitude'].values.tolist() #get longitude form metadata\n",
    "        sta_lons.append(lon[0]) #append\n",
    "        \n",
    "        netsta_names.append(md_netsta.upper()) # make list of station names\n",
    "\n",
    "\n",
    "    # define grid origin in lat,lon\n",
    "    \n",
    "    #finding bottom left corner of grid map\n",
    "    lat_start = volc_lat_lon[volc_list_names[vv]][0] - (grid_length/222000) #volcano lat minus half of grid length in decimal lat long\n",
    "    lon_start = volc_lat_lon[volc_list_names[vv]][1] - (grid_height/222000) #volcano long minus half of grid height in decimal lat long\n",
    "        \n",
    "    #station lat lons to x y\n",
    "    sta_x = []\n",
    "    sta_y = []\n",
    "    for i in range(len(sta_lats)):\n",
    "        x_dist = distance.distance([lat_start,lon_start],[lat_start,sta_lons[i]]).m\n",
    "        y_dist = distance.distance([lat_start,lon_start],[sta_lats[i],lon_start]).m\n",
    "        sta_x.append(x_dist)\n",
    "        sta_y.append(y_dist)\n",
    "\n",
    "    # set grid points\n",
    "    x_vect = np.arange(0, grid_length, step)\n",
    "    y_vect = np.arange(0, grid_height, step)\n",
    "    t0 = np.arange(0,np.max(arrivals),t_step)\n",
    "    vs = np.arange(vs_min,vs_max,vs_step)\n",
    "\n",
    "    print('yo')\n",
    "    # carry out the gridsearch\n",
    "    rss_mat = gridsearch(t0,x_vect,y_vect,sta_x,sta_y,vs,arrivals)\n",
    "    print('here')\n",
    "    # find lowest error lat, lon, and origin time\n",
    "    loc_idx = np.unravel_index([np.argmin(rss_mat)], rss_mat.shape)\n",
    "    \n",
    "    # find the lat and lon of the location index\n",
    "    loc_lat, loc_lon, d = location(x_vect[loc_idx[1]], y_vect[loc_idx[2]], lat_start, lon_start)\n",
    "    err_thr = np.min(np.log10(rss_mat))+.05\n",
    "    thr_array = np.argwhere(np.log10(rss_mat)<err_thr)\n",
    "    diameter = error_diameter(thr_array)\n",
    "    \n",
    "    print('location lat lon',loc_lat,loc_lon)\n",
    "\n",
    "    # plot a spatial map of error for lowest-error origin time\n",
    "#     fig,ax = plt.subplots()\n",
    "#     ax.scatter(x_vect[loc_idx[1]],y_vect[loc_idx[2]],s=100,marker='*',c='r')\n",
    "#     im = ax.imshow(np.log10(rss_mat[loc_idx[0],:,:].T),origin=\"lower\",extent=[0,grid_length,0,grid_height])\n",
    "#     fig.colorbar(im)\n",
    "#     plt.show()\n",
    "    \n",
    "    row = [volc_list_names[vv],' '.join(netsta_names),' '.join([str(i) for i in arrivals]),cl,loc_lat,loc_lon]\n",
    "    with open(homedir+f'/locations/{volc_list_names[vv]}_Template_Locations.csv', 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "        file.close()\n",
    "    \n",
    "    stopwatch1=time() #note the time\n",
    "    print(f'{stopwatch1-stopwatch0} s for this cluster') #print time it took to go through this cluster\n",
    "    \n",
    "    #write into csv relative picktimes in seconds after first_sta, probably list separated by \n",
    "    #spaces, like how stations are saved in events, make sure index is same for the template \n",
    "    #name and picktime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae80e1f",
   "metadata": {},
   "source": [
    "Compare to ComCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = 11 #51 is a cluster on hood with no matches\n",
    "url = f'https://assets.pnsn.org/red/hood/clusters/{cl}.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53695837",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)\n",
    "\n",
    "matches = str(r.content.splitlines()[20]).split('Potential local match:')[1:]\n",
    "\n",
    "c_times = []\n",
    "c_lats = []\n",
    "c_lons = []\n",
    "if len(matches)>0:\n",
    "    for m in matches:\n",
    "        m_feats = m.split(' ')\n",
    "        m_time = m_feats[1]\n",
    "        c_times.append(m_time)\n",
    "        m_lat = float(m_feats[2][1:-1])\n",
    "        c_lats.append(m_lat)\n",
    "        m_lon = float(m_feats[3][:-1])\n",
    "        c_lons.append(m_lon)\n",
    "        print(f'TIME {m_time} LAT {m_lat} LON {m_lon}')\n",
    "\n",
    "else:\n",
    "    print('no ComCat matches')\n",
    "    \n",
    "avg_c_lat = np.average(c_lats)\n",
    "avg_c_lon = np.average(c_lons)\n",
    "print(f'Average ComCat Location lat {avg_c_lat} lon {avg_c_lon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ec052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ComCat and my locations to compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo-py38-shared"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

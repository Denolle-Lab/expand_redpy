{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcefe0d8",
   "metadata": {},
   "source": [
    "# currently set up for siletzia, change data pathway for cascadia\n",
    "\n",
    "Created: July 14, 2022\n",
    "Updated: August 11, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3021b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched-filter CPU is not compiled! Should be here: /home/jupyter_share/miniconda3/envs/seismo/lib/python3.8/site-packages/fast_matched_filter/lib/matched_filter_CPU.so\n"
     ]
    }
   ],
   "source": [
    "# import everything\n",
    "import yaml\n",
    "import numpy as np\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "# %matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"/data/wsd01/pnwstore/\")\n",
    "import eqcorrscan\n",
    "from eqcorrscan.core.match_filter import match_filter\n",
    "from eqcorrscan.core.match_filter.tribe import Tribe\n",
    "from time import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from obspy.core.utcdatetime import UTCDateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c7b135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/smocz/expand_redpy/scripts/config.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "# Template metadata\n",
    "fqmin = config['fqmin']\n",
    "fqmax = config['fqmax']\n",
    "fs = config['fs']\n",
    "prepick_len = config['prepick_len']\n",
    "trig_int = config['trig_int']\n",
    "thr_t = config['thr_t']\n",
    "thr = config['thr']\n",
    "xfunc = config['xfunc']\n",
    "plot = config['plot']\n",
    "r_st = config['r_st']\n",
    "i_b_d = config['i_b_d']\n",
    "overlap = config['overlap']\n",
    "metric = config['metric']\n",
    "\n",
    "homedir = config['homedir']\n",
    "datadir = config['datadir']\n",
    "readdir = config['readdir']\n",
    "\n",
    "year = config['year']\n",
    "vv = config['vv']\n",
    "chan = config['chan']\n",
    "\n",
    "# tribe = eqcorrscan.core.match_filter.tribe.Tribe(templates = stack_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad20a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "volc_md = pd.read_csv(readdir+'Volcano_Metadata.csv') # read metadata file to create dataframe of labels\n",
    "volc_md['netsta'] = volc_md['Network'].astype(str)+'.'+volc_md['Station'].astype(str)\n",
    "# create lists of stations used at each volcano/for each data file\n",
    "\n",
    "Baker_sta = volc_md[volc_md['Volcano_Name'] == 'Baker']['netsta'].values.tolist()\n",
    "Hood_sta = volc_md[volc_md['Volcano_Name'] == 'Hood']['netsta'].values.tolist() # missing from Volcano_Metadata.csv\n",
    "St_Helens_sta = volc_md[volc_md['Volcano_Name'] == 'St_Helens']['netsta'].values.tolist()\n",
    "Newberry_sta = volc_md[volc_md['Volcano_Name'] == 'Newberry']['netsta'].values.tolist() # missing from Volcano_Metadata.csv\n",
    "Rainier_sta = volc_md[volc_md['Volcano_Name'] == 'Rainier']['netsta'].values.tolist()\n",
    "\n",
    "#create list of volcanoes\n",
    "\n",
    "volc_list_names = ['Baker','Hood','St_Helens','Newberry','Rainier'] # list of names of each volcano\n",
    "volc_sta = [Baker_sta,Hood_sta,St_Helens_sta,Newberry_sta,Rainier_sta] # lists of stations connected to respective volcanoes\n",
    "# print(volc_sta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fe43d",
   "metadata": {},
   "source": [
    "### Run the templates over a year - loop through multiple tribes - integrate saving as a csv - Jul 14, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8350cb",
   "metadata": {},
   "source": [
    "Save as .py files to run on terminal - divide up into each volcano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops through julian days\n",
    "# run over a year\n",
    "\n",
    "# for vv,v in enumerate(volc_sta):\n",
    "v = volc_sta[vv]\n",
    "for s in range(0,len(v)): #usually 0,len(Hood_sta)\n",
    "    net, sta =  v[s].split('.') #add specific network per station\n",
    "    print(station)\n",
    "    print(volc_list_names[vv])\n",
    "    try:\n",
    "        T = Tribe().read(*glob(homedir+'/templates/Volcano_'+volc_list_names[vv]+'_Network'+net+'_Station_'+sta+'_Channel_*.tgz'))\n",
    "        print(T)\n",
    "    except:\n",
    "        print('No Tribe for Station')\n",
    "        continue\n",
    "    try:\n",
    "        obspy.read(glob(f'{datadir}{year}/*/{sta}/{sta}.{net}.{year}.*')[0]).select(channel=chan)\n",
    "    except:\n",
    "        print('No Data for Station')\n",
    "        continue\n",
    "    with open(homedir+'/detections/'+volc_list_names[vv]+'_'+v[s]+'_'+str(year)+'_detections.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"ID\", \"Template_Name\", \"Detection_Time\"])\n",
    "        file.close()\n",
    "    for i in range(1,366): # normally 1,366\n",
    "        parties = []\n",
    "        t0=time()\n",
    "        st = obspy.read(*glob(f'{datadir}{year}/*/{sta}/{sta}.{net}.{year}.{str(i).zfill(3)}')).select(channel=chan)\n",
    "        st.detrend(type='demean')\n",
    "        st.resample(fs)\n",
    "        st.filter(type='bandpass',freqmin=fqmin,freqmax=fqmax)\n",
    "        st.merge(fill_value=0)\n",
    "        t1=time()\n",
    "        print(\"it tooks %2f s to download data\" %(t1-t0))\n",
    "        print(st)\n",
    "        print(str(year)+str(i).zfill(3))\n",
    "        for ii in range(0,len(T.templates)):\n",
    "            T.templates[ii].prepick = prepick_len \n",
    "        if len(st)==0: continue\n",
    "        try:\n",
    "            party = T.detect(stream=st,starttime=st[0].stats.starttime,endtime=st[-1].stats.endtime,threshold=thr, threshold_type=thr_t,xcorr_func = xfunc,trig_int=trig_int, plot=plot, return_stream=r_st, ignore_bad_data=i_b_d,overlap=overlap)\n",
    "        except:\n",
    "            continue\n",
    "        party.decluster(metric=metric,trig_int=trig_int) #had to add trig_int, it is minimum detection separation in seconds\n",
    "        t2=time()\n",
    "        print(\"it tooks %2f s to launch the party\" %(t2-t1))\n",
    "        print(party)\n",
    "        print(len(party))\n",
    "        if len(party) > 0: \n",
    "            print(party[0])\n",
    "            print(party.families)\n",
    "            parties.append(party)\n",
    "            for ii in range(0,len(parties[0].families)):\n",
    "                for iii in range(0,len(parties[0].families[ii].detections)):\n",
    "                    row = [str(parties[0].families[ii].detections[iii].id),\n",
    "                           str(parties[0].families[ii].detections[iii].template_name),\n",
    "                           str(parties[0].families[ii].detections[iii].detect_time)]\n",
    "                    with open(homedir+'/detections/'+volc_list_names[vv]+'_'+v[s]+'_'+str(year)+'_detections.csv', 'a',\n",
    "                              newline='') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow(row)\n",
    "                        file.close()\n",
    "#         break\n",
    "#    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

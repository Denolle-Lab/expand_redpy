{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcefe0d8",
   "metadata": {},
   "source": [
    "# currently set up for siletzia, change data pathway for cascadia\n",
    "\n",
    "Created: July 14, 2022\n",
    "Updated: October 25, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3021b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched-filter CPU is not compiled! Should be here: /home/jupyter_share/miniconda3/envs/seismo/lib/python3.8/site-packages/fast_matched_filter/lib/matched_filter_CPU.so\n"
     ]
    }
   ],
   "source": [
    "# import everything\n",
    "import yaml\n",
    "import numpy as np\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "# %matplotlib inline\n",
    "# import sys\n",
    "# sys.path.append(\"/data/wsd01/pnwstore/\")\n",
    "import eqcorrscan\n",
    "from eqcorrscan.core.match_filter import match_filter\n",
    "from eqcorrscan.core.match_filter.tribe import Tribe\n",
    "from time import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from obspy.core.utcdatetime import UTCDateTime\n",
    "client = Client('IRIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7b135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/smocz/expand_redpy/scripts/config.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "# Template metadata\n",
    "fqmin = config['fqmin']\n",
    "fqmax = config['fqmax']\n",
    "fs = config['fs']\n",
    "prepick_len = config['prepick_len']\n",
    "trig_int = config['trig_int']\n",
    "thr_t = config['thr_t']\n",
    "thr = config['thr']\n",
    "xfunc = config['xfunc']\n",
    "plot = config['plot']\n",
    "r_st = config['r_st']\n",
    "i_b_d = config['i_b_d']\n",
    "overlap = config['overlap']\n",
    "metric = config['metric']\n",
    "\n",
    "homedir = config['homedir']\n",
    "datadir = config['datadir']\n",
    "readdir = config['readdir']\n",
    "\n",
    "# year = config['year']\n",
    "years = config['years']\n",
    "vv = config['vv']\n",
    "chan = config['chan']\n",
    "\n",
    "# tribe = eqcorrscan.core.match_filter.tribe.Tribe(templates = stack_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad20a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "volc_md = pd.read_csv(readdir+'Volcano_Metadata.csv') # read metadata file to create dataframe of labels\n",
    "volc_md['netsta'] = volc_md['Network'].astype(str)+'.'+volc_md['Station'].astype(str)\n",
    "# create lists of stations used at each volcano/for each data file\n",
    "\n",
    "Baker_sta = volc_md[volc_md['Volcano_Name'] == 'Baker']['netsta'].values.tolist()\n",
    "Hood_sta = volc_md[volc_md['Volcano_Name'] == 'Hood']['netsta'].values.tolist() # missing from Volcano_Metadata.csv\n",
    "St_Helens_sta = volc_md[volc_md['Volcano_Name'] == 'St_Helens']['netsta'].values.tolist()\n",
    "Newberry_sta = volc_md[volc_md['Volcano_Name'] == 'Newberry']['netsta'].values.tolist() # missing from Volcano_Metadata.csv\n",
    "Rainier_sta = volc_md[volc_md['Volcano_Name'] == 'Rainier']['netsta'].values.tolist()\n",
    "\n",
    "#create list of volcanoes\n",
    "\n",
    "volc_list_names = ['Baker','Hood','Newberry','Rainier','St_Helens'] # list of names of each volcano\n",
    "volc_sta = [Baker_sta,Hood_sta,Newberry_sta,Rainier_sta,St_Helens_sta] # lists of stations connected to respective volcanoes\n",
    "# print(volc_sta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fe43d",
   "metadata": {},
   "source": [
    "### Run the templates over a year - loop through multiple tribes - integrate saving as a csv - Oct 25, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8350cb",
   "metadata": {},
   "source": [
    "Save as .py files to run on terminal - divide up into each volcano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t00 = time()\n",
    "\n",
    "# loops through julian days\n",
    "# run over several years\n",
    "for year in years:\n",
    "    print(f\"YEAR: {year}\")\n",
    "    # for vv,v in enumerate(volc_sta):\n",
    "    v = volc_sta[vv]\n",
    "    for s in range(0,len(v)): #usually 0,len(Hood_sta)\n",
    "        net, sta =  v[s].split('.') #add specific network per station\n",
    "        print(net,sta)\n",
    "        print(volc_list_names[vv])\n",
    "        try:\n",
    "            T = Tribe().read(*glob(homedir+'templates/Volcano_'+volc_list_names[vv]+'_Network_'+net+'_Station_'+sta+'_Channel_*.tgz'))\n",
    "            print(T)\n",
    "        except:\n",
    "            print('No tgz for Station')\n",
    "            continue\n",
    "#         try:\n",
    "#             obspy.read(glob(f'{datadir}{year}/{net}/{sta}/{sta}.{net}.{year}.*')[0]).select(channel=chan)\n",
    "#         except:\n",
    "#             print('No Data for Station')\n",
    "#             continue\n",
    "        if UTCDateTime(volc_md[volc_md['netsta']==v[s]]['Starttime'].values.tolist()[0]).year <= year: #if the year of the startime of this station is less than or equal to the year we are running\n",
    "            if UTCDateTime(volc_md[volc_md['netsta']==v[s]]['Endtime'].values.tolist()[0]).year >= year: #if the year of the endtime is greater than or equal to the year we are running\n",
    "                with open(homedir+'detections/'+volc_list_names[vv]+'_'+v[s]+'_'+str(year)+'_detections.csv', 'w', newline='') as file: # if both are true, create csv\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow([\"ID\", \"Template_Name\", \"Detection_Time\"])\n",
    "                    file.close()\n",
    "            else: #if endtime statement is NOT true\n",
    "                continue #skip this station for this year\n",
    "        else: #if starttime statement is NOT true\n",
    "            continue #skip this station for this year\n",
    "        for i in range(1,366): # normally 1,366\n",
    "            print('------')\n",
    "            parties = []\n",
    "            t0=time()\n",
    "#             st = obspy.read(*glob(f'{datadir}{year}/*/{sta}/{sta}.{net}.{year}.{str(i).zfill(3)}')).select(channel=chan)\n",
    "            sst = UTCDateTime(year=year,julday=i,hour=0,minute=0,second=0)\n",
    "            try:\n",
    "                st = client.get_waveforms(network=net, station=sta, channel=chan, location='*',starttime=sst, endtime=sst+86400)\n",
    "            except:\n",
    "                print('No data available for request.')\n",
    "                continue\n",
    "            st.detrend(type='demean')\n",
    "            st.resample(fs)\n",
    "            st.filter(type='bandpass',freqmin=fqmin,freqmax=fqmax)\n",
    "            st.merge(fill_value=0)\n",
    "            t1=time()\n",
    "            print(\"it tooks %2f s to download data\" %(t1-t0))\n",
    "            print(st)\n",
    "            print(str(year)+str(i).zfill(3))\n",
    "            for ii in range(0,len(T.templates)):\n",
    "                T.templates[ii].prepick = prepick_len \n",
    "            if len(st)==0: continue\n",
    "            try:\n",
    "                party = T.detect(stream=st,starttime=st[0].stats.starttime,endtime=st[-1].stats.endtime,threshold=thr,     \\\n",
    "                                 threshold_type=thr_t,xcorr_func = xfunc,trig_int=trig_int, plot=plot, return_stream=r_st, \\\n",
    "                                 ignore_bad_data=i_b_d,overlap=overlap)\n",
    "            except:\n",
    "                print('can\\'t detect')\n",
    "                continue\n",
    "            party.decluster(metric=metric,trig_int=trig_int) #had to add trig_int, it is minimum detection separation in seconds\n",
    "            t2=time()\n",
    "            print(f\"it tooks {t2-t1} s to launch the party\")\n",
    "            print(party)\n",
    "            print('detections:',len(party))\n",
    "            if len(party) > 0: \n",
    "                print(party[0])\n",
    "                print(party.families)\n",
    "                parties.append(party)\n",
    "                for ii in range(0,len(parties[0].families)):\n",
    "                    for iii in range(0,len(parties[0].families[ii].detections)):\n",
    "                        row = [str(parties[0].families[ii].detections[iii].id),\n",
    "                               str(parties[0].families[ii].detections[iii].template_name),\n",
    "                               str(parties[0].families[ii].detections[iii].detect_time)]\n",
    "                        with open(homedir+'detections/'+volc_list_names[vv]+'_'+v[s]+'_'+str(year)+'_detections.csv', 'a',\n",
    "                                  newline='') as file:\n",
    "                            writer = csv.writer(file)\n",
    "                            writer.writerow(row)\n",
    "                            file.close()\n",
    "    #         break\n",
    "    #    break\n",
    "t01 = time()\n",
    "print(f'number of days to run detections at this volcano: {(t01-t00)/86400}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo-py38-shared"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

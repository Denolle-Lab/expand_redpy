{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcefe0d8",
   "metadata": {},
   "source": [
    "# set up for siletzia, change data pathway for cascadia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3021b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything\n",
    "\n",
    "import numpy as np\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "# %matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"/data/wsd01/pnwstore/\")\n",
    "import eqcorrscan\n",
    "from eqcorrscan.core.match_filter import match_filter\n",
    "from eqcorrscan.core.match_filter.tribe import Tribe\n",
    "from time import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from obspy.core.utcdatetime import UTCDateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad20a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "volc_md = pd.read_csv('Volcano_Metadata.csv') # read metadata file to create dataframe of labels\n",
    "\n",
    "# create lists of stations used at each volcano/for each data file\n",
    "\n",
    "Baker_sta = volc_md[volc_md['Volcano_Name'] == 'Mt_Baker']['Station'].values.tolist()\n",
    "Hood_sta = volc_md[volc_md['Volcano_Name'] == 'Mt_Hood']['Station'].values.tolist() # missing from Volcano_Metadata.csv\n",
    "St_Helens_sta = volc_md[volc_md['Volcano_Name'] == 'Mt_St_Helens']['Station'].values.tolist()\n",
    "Newberry_sta = volc_md[volc_md['Volcano_Name'] == 'Newberry']['Station'].values.tolist() # missing from Volcano_Metadata.csv\n",
    "Rainier_sta = volc_md[volc_md['Volcano_Name'] == 'Mt_Rainier']['Station'].values.tolist()\n",
    "\n",
    "#create list of volcanoes\n",
    "\n",
    "volc_list_names = ['Baker','Hood','St_Helens','Newberry','Rainier'] # list of names of each volcano\n",
    "volc_sta = [Baker_sta,Hood_sta,St_Helens_sta,Newberry_sta,Rainier_sta] # lists of stations connected to respective volcanoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter based on distance and then stack all earthquakes in a group to create a template\n",
    "\n",
    "# Template metadata\n",
    "fqmin = 1\n",
    "fqmax = 10\n",
    "fs=40\n",
    "prepick_len = 0.3\n",
    "trig_int = 6\n",
    "\n",
    "homedir = '/home/smocz/redpy_expand_new_files/' #home directory or directory to save new files to\n",
    "datadir = '/data/wsd01/HOOD_data/UW/2019/' #directory to get data from\n",
    "\n",
    "year = 2019\n",
    "\n",
    "# tribe = eqcorrscan.core.match_filter.tribe.Tribe(templates = stack_templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fe43d",
   "metadata": {},
   "source": [
    "### Run the templates over a year - loop through multiple tribes - integrate saving as a csv - Jul 14, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8350cb",
   "metadata": {},
   "source": [
    "Save as .py files to run on terminal - divide up into each volcano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops through julian days\n",
    "# run over a year\n",
    "\n",
    "# for vv,v in enumerate(volc_sta):\n",
    "v = Hood_sta\n",
    "vv = 1\n",
    "for s in range(0,7): #usually 0,len(Hood_sta)\n",
    "    station = v[s]\n",
    "    print(station)\n",
    "    print(volc_list_names[vv])\n",
    "    try:\n",
    "        T = Tribe().read(*glob(homedir+'/templates/Volcano_'+volc_list_names[vv]+'_Station_'+station+'_Channel_*.tgz'))\n",
    "        print(T)\n",
    "    except:\n",
    "        print('No Tribe for Station')\n",
    "        continue\n",
    "    try:\n",
    "        obspy.read(glob(datadir+'*/'+station+'.*.'+str(year)+'.*')[0])\n",
    "    except:\n",
    "        print('No Data for Station')\n",
    "        continue\n",
    "    with open(homedir+'/detections/'+volc_list_names[vv]+'_'+v[s]+'_'+str(year)+'_detections.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"ID\", \"Template_Name\", \"Detection_Time\"])\n",
    "        file.close()\n",
    "    for i in range(1,366): # normally 1,366\n",
    "        parties = []\n",
    "        t0=time()\n",
    "        st = obspy.read(*glob(datadir+str(i).zfill(3)+'/'+station+'.*.'+str(year)+'.*'))\n",
    "        st.select(component=\"Z\") #Use only the Z Component\n",
    "        st.detrend(type='demean')\n",
    "        st.resample(fs)\n",
    "        st.filter(type='bandpass',freqmin=fqmin,freqmax=fqmax)\n",
    "        st.merge(fill_value=0)\n",
    "        t1=time()\n",
    "        print(\"it tooks %2f s to download data\" %(t1-t0))\n",
    "        print(st)\n",
    "        print(str(year)+str(i).zfill(3))\n",
    "        for ii in range(0,len(T.templates)):\n",
    "            T.templates[ii].prepick = prepick_len \n",
    "        if len(st)==0: continue\n",
    "        try:\n",
    "            party = T.detect(stream=st,starttime=st[0].stats.starttime,endtime=st[0].stats.endtime,threshold=0.6, threshold_type='absolute',xcorr_func = 'fmf',trig_int=trig_int, plot=False, return_stream=False, ignore_bad_data=True,overlap='calculate')\n",
    "        except:\n",
    "            continue\n",
    "        party.decluster(metric='avg_cor',trig_int=trig_int) #had to add trig_int, it is minimum detection separation in seconds\n",
    "        t2=time()\n",
    "        print(\"it tooks %2f s to launch the party\" %(t2-t1))\n",
    "        print(party)\n",
    "        print(len(party))\n",
    "        if len(party) > 0: \n",
    "            print(party[0])\n",
    "            print(party.families)\n",
    "            parties.append(party)\n",
    "            for ii in range(0,len(parties[0].families)):\n",
    "                for iii in range(0,len(parties[0].families[ii].detections)):\n",
    "                    row = [str(parties[0].families[ii].detections[iii].id),\n",
    "                           str(parties[0].families[ii].detections[iii].template_name),\n",
    "                           str(parties[0].families[ii].detections[iii].detect_time)]\n",
    "                    with open(homedir+'/detections/'+volc_list_names[vv]+'_'+v[s]+'_'+str(year)+'_detections.csv', 'a',\n",
    "                              newline='') as file:\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow(row)\n",
    "                        file.close()\n",
    "#         break\n",
    "#    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

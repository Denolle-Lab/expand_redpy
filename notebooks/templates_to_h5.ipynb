{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a5eaf8",
   "metadata": {},
   "source": [
    "Code to make h5 files of the templates in the case that they are not saved correctly during make_templates\n",
    "\n",
    "Created December 7, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26412a3e",
   "metadata": {},
   "source": [
    "Imports and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #to work with csv\n",
    "import numpy as np #for some math in stream data\n",
    "import eqcorrscan #the package for templates\n",
    "from eqcorrscan import Tribe #import the ability to read .tgz files aka Tribe files\n",
    "import obspy #import obspy to work with streams, etc.\n",
    "import h5py #for writing to h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a01334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters - WILL BE UPDATED TO READ CONFIG\n",
    "path = '/home/smocz/expand_redpy_new_files/templates/' #path to .tgz file\n",
    "filename = 'Volcano_Rainier_Network_UW_Station_RCM_Channel_HHZ.tgz' #name of .tgz file\n",
    "nbucket = 1\n",
    "savepath = '/data/wsd03/redpy_template_h5/' #path to save to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8195836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in volcano metadata for station location\n",
    "volc_md = pd.read_csv('/home/smocz/expand_redpy/csv_catalogs/Volcano_Metadata.csv')\n",
    "#make associated netsta column\n",
    "volc_md['netsta'] = volc_md['Network'].astype(str)+'.'+volc_md['Station'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0775e5e",
   "metadata": {},
   "source": [
    "Retreive templates (see reading_templates for more details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5cc2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Tribe().read(f'{path}{filename}') #read the .tgz file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260cb9d",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e34e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dictionary data and DataFrame meta\n",
    "data=np.zeros((len(T),len(T[0].st[0].data))) #size is number of templates, length of template stream data \n",
    "#(length data is same for all templates)\n",
    "meta = pd.DataFrame(columns = [\n",
    "    \"source_id\", \"source_origin_time\", \"source_latitude_deg\", \"source_longitude_deg\", \"source_type\",\n",
    "    \"source_depth_km\", \"split\", \"source_magnitude\", \"station_network_code\", \"trace_channel\", \n",
    "    \"station_code\", \"station_location_code\", \"station_latitude_deg\",  \"station_longitude_deg\",\n",
    "    \"station_elevation_m\", \"trace_name\", \"trace_sampling_rate_hz\", \"trace_start_time\",\n",
    "    \"trace_S_arrival_sample\", \"trace_P_arrival_sample\", \"CODE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe1805",
   "metadata": {},
   "source": [
    "Fill in data and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt,t in enumerate(T): #for each template in the tgz file\n",
    "    print(tt)\n",
    "    ############################\n",
    "    #gather and append metadata#\n",
    "    ############################\n",
    "    \n",
    "    #source_id/clusterID, cl_id:\n",
    "    volc = filename.split('_')[1] #get volcano name from filename\n",
    "    if volc=='Baker' or volc=='Hood' or volc=='Newberry' or volc=='Rainier': #account for zfill\n",
    "        cl_id = t.name[-3:] #record clusterID\n",
    "    if filename.partition('_')[1]=='St_Helens':#account for zfill\n",
    "        cl_id = t.name[-4:] #record clusterID\n",
    "    \n",
    "    #network, net:\n",
    "    net = filename.split('_')[3] #get network from filename\n",
    "    \n",
    "    #station, sta:\n",
    "    sta = filename.split('_')[5] #get station from filename\n",
    "    \n",
    "    #channel, chan:\n",
    "    chan = filename.split('_')[-1].split('.')[0] #get channel from filename, use second split to ignore \".tgz\"\n",
    "    \n",
    "    #latitude and longitude, lat lon:\n",
    "    lat = volc_md[volc_md['netsta']==f'{net}.{sta}']['Latitude'].values.tolist()[0]\n",
    "    lon = volc_md[volc_md['netsta']==f'{net}.{sta}']['Longitude'].values.tolist()[0]\n",
    "\n",
    "    print(f'template name: {t.name}, source_id: {cl_id}, network: {net}, station: {sta}, channel: {chan}, latitude: {lat}, longitude: {lon}')\n",
    "    print('----------')\n",
    "    \n",
    "    meta = meta.append({\"source_id\": cl_id, \"source_origin_time\": '', \n",
    "        \"source_latitude_deg\": \"%.3f\" % 0, \"source_longitude_deg\": \"%.3f\" % 0, \n",
    "        \"source_type\": 'unknown',\n",
    "        \"source_depth_km\": \"%.3f\" % 0, \"source_magnitude\": 0,\n",
    "        \"station_network_code\": net, \"trace_channel\": chan, \n",
    "        \"station_code\": sta, \"station_location_code\": '',\n",
    "        \"station_latitude_deg\": lat,  \"station_longitude_deg\": lon,\n",
    "        \"station_elevation_m\": 0,\n",
    "        \"trace_p_arrival_sample\": 0, \"CODE\": t.name}, ignore_index = True)\n",
    "    \n",
    "    ########################\n",
    "    #gather and append data#\n",
    "    ########################\n",
    "    \n",
    "    data[tt] = t.st[0]\n",
    "    \n",
    "#     break\n",
    "\n",
    "\n",
    "#save meta to csv\n",
    "meta.to_csv(f\"{savepath}meta_csv/{filename.split('.')[0]}.csv\",sep = ',', index=False)\n",
    "\n",
    "#write to h5\n",
    "with h5py.File(f\"{savepath}h5/{filename.split('.')[0]}.hdf5\",'w') as f:\n",
    "    f['/data'] = data\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a419fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "display(meta)\n",
    "print(data[0])\n",
    "print('---')\n",
    "print(data[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo-py38-shared"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48e909c",
   "metadata": {},
   "source": [
    "Created June 21, 2023\n",
    "\n",
    "Updated Aug 1, 2023\n",
    "\n",
    "### Created to plot the results of kmeans grouping the redpy clusters spatially and temporally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np #for math and np.unique\n",
    "import pandas as pd #for dataframes and reading/saving csvs\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "import rasterio as rio #for reading in DEM\n",
    "from rasterio.plot import show #for plotting with rio\n",
    "from matplotlib.gridspec import GridSpec #for organizing subplots\n",
    "import math #for organizing subplots (math.ciel and math.floor)\n",
    "import h5py #for reading in waveforms\n",
    "import yaml #for reading in config\n",
    "from glob import glob #for pulling in multiple event csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b641fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config params\n",
    "with open('/home/smocz/expand_redpy/scripts/config.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "homedir = config['homedir']\n",
    "readdir = config['readdir']\n",
    "\n",
    "vv = config['vv']\n",
    "volc_list_names = config['volc_list_names']\n",
    "volc = volc_list_names[vv]\n",
    "print(volc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d24a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params to chose\n",
    "#pull in cop-kmeans results (code currently on laptop which has the cop kmeans package installed)\n",
    "k = 6\n",
    "#set station to look at waveforms from\n",
    "sta = 'hood' #must be lowercase, must be at the volcano you are looking at, see Volcano_Metadata.csv for options\n",
    "#number of states for fingerprint\n",
    "states = 60\n",
    "#kmeans file name, set manually or let k and sta pull it in\n",
    "# kmeans_filename = 'Hood_HOOD_cop_kmeans.csv'\n",
    "kmeans_filename = f'tsne_{volc}_k_{k}_cl_grps_{states}_states.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull things in from params\n",
    "cl_k_grp = pd.read_csv(f'{homedir}cop_kmeans/{kmeans_filename}')\n",
    "if type(cl_k_grp['cluster_id'].values[0])==np.int64: #if cluster ids were saved as an int\n",
    "    print('type int')\n",
    "    cl_k_grp['cluster_id']=[f'b\\'{str(i).zfill(3)}\\'' for i in cl_k_grp['cluster_id']] #immitate byte for formatting consistency\n",
    "\n",
    "#pull in cluster locations\n",
    "locs = pd.read_csv(f'{homedir}locations/{volc}_Template_Locations.csv')\n",
    "#pull volcano metadata for station location\n",
    "volc_md = pd.read_csv(f'{readdir}Volcano_Metadata.csv')\n",
    "\n",
    "#pull in event catalog\n",
    "if volc == 'St_Helens': #for Helens, must concat catalogs, same code as in make_templates\n",
    "    St_Helens = pd.read_csv(readdir+'MountStHelens_catalog.csv')\n",
    "    # Combining borehole and local catalogs with St_Helens\n",
    "    Helens_Borehole = pd.read_csv(readdir+'MSHborehole_catalog.csv')\n",
    "    Helens_Borehole['Clustered'] += 2000 \n",
    "    # Cluster 0 in Helens_Borehole is now Cluster 2000 in St_Helens\n",
    "    Helens_Local = pd.read_csv(readdir+'MSHlocal_catalog.csv')\n",
    "    Helens_Local['Clustered'] += 3000\n",
    "    # Cluster 0 in Helens_Local is now Cluster 3000 in St_Helens\n",
    "    # Use St_Helens to access all three St Helens catalogs\n",
    "    volc_ctlg = pd.concat([St_Helens,Helens_Borehole,Helens_Local])\n",
    "else:\n",
    "    volc_ctlg = pd.read_csv(f'/home/smocz/expand_redpy/csv_catalogs/{volc}_catalog.csv')\n",
    "\n",
    "if volc_md[volc_md[\"Station\"]==sta.upper()][\"Volcano_Name\"].values.tolist()[0] != volc: print('STATION IS NOT AT THE PROPER VOLCANO')\n",
    "sta_lat = volc_md[volc_md[\"Station\"]==sta.upper()][\"Latitude\"].values.tolist()[0]\n",
    "sta_lon = volc_md[volc_md[\"Station\"]==sta.upper()][\"Longitude\"].values.tolist()[0]\n",
    "print(sta,sta_lat,sta_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8435013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_k_grp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ba98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in waveforms\n",
    "with h5py.File(f\"/home/smocz/expand_redpy_new_files/h5/new_normalized_{volc.lower()}_templates_{states}_states.h5\", \"r\") as f: #pull in fingerprints\n",
    "    fingerprints = f[\"fingerprints\"][()]\n",
    "    template_name = f[\"template_name\"][()]\n",
    "    waveforms = f[\"waveforms\"][()]\n",
    "    print(f.keys()) #print what data is in this file\n",
    "    \n",
    "print(template_name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd2817",
   "metadata": {},
   "source": [
    "### Location (DEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d5870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get locations of clusters\n",
    "cl_list = [] #will be a list of all clusters with locations\n",
    "kmeans_grp = [] #will be a list of the kmeans group for each cluster saved\n",
    "lats = [] #will be a list of all latitude points (indexes match with cl_list)\n",
    "lons = [] #will be a list of all longitude points (indexes match with cl_list)\n",
    "for cc,cl in enumerate(cl_k_grp['cluster_id'].values.tolist()):\n",
    "#     print('---')\n",
    "#     print('cl',int(cl[2:-1]))\n",
    "    try:\n",
    "        lat = locs[locs[\"Cluster_ID\"]==int(cl[2:-1])][\"Latitude\"].item() #get the associated latitude\n",
    "        lats.append(lat) #append\n",
    "        lon = locs[locs[\"Cluster_ID\"]==int(cl[2:-1])][\"Longitude\"].item() #get the associated longitude\n",
    "        lons.append(lon) #append\n",
    "        cl_list.append(cl[2:-1]) #append cl id\n",
    "        kmeans_grp.append(cl_k_grp['kmeans_grp'].values.tolist()[cc]) #append kmeans id\n",
    "#         print(lat,lon)\n",
    "    except:\n",
    "#         print('no location')\n",
    "        continue\n",
    "\n",
    "locdf = pd.DataFrame({\"cluster_id\":cl_list,\"kmeans_grp\":kmeans_grp,\"latitude\":lats,\"longitude\":lons}) #create df\n",
    "locdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65b383f",
   "metadata": {},
   "source": [
    "Plot locations on DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af5abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up info for DEM plot\n",
    "dem = rio.open(\"/home/smocz/expand_redpy_new_files/DEM_data/Hood.tif\") #open tif file with rio\n",
    "dem_array = dem.read(1).astype('float64') #set array for DEM\n",
    "crs = dem.crs #get crs (coordinate reference systems)\n",
    "dem_data_dict={'data':dem_array, 'crs':crs, 'left':dem.bounds[0], 'right':dem.bounds[2], 'bottom':dem.bounds[1],\n",
    "               'top':dem.bounds[3]} #extract boundaries\n",
    "#set volcano center\n",
    "center_lat = 46.8528857\n",
    "center_lon = -121.7603744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9480e03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = dem_data_dict['data']\n",
    "left,right,bottom,top = dem_data_dict['left'],dem_data_dict['right'],\\\n",
    "                        dem_data_dict['bottom'],dem_data_dict['top']\n",
    "\n",
    "ncols = math.ceil(k/2) #number of columns for the map plot, based on k or can be entered manually\n",
    "nrows = math.ceil(k/ncols) #determines number of rows needed by rounding up to nearest whole number\n",
    "\n",
    "fig, ax0 = plt.subplots(figsize=(ncols*10,nrows*8))\n",
    "gs = GridSpec(nrows, ncols, figure=fig) #make GridSpec for formatting subplots, based on ncols and nrows\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "for aa in range(0,k):#for each subplot\n",
    "    ax = fig.add_subplot(gs[math.floor(aa/ncols):math.floor(aa/ncols)+1, \\\n",
    "            aa - math.floor(aa/ncols)*ncols:aa - math.floor(aa/ncols)*ncols +1]) #add subplot\n",
    "    \n",
    "    ax.imshow(data,extent=[left, right, bottom, top],cmap='gist_earth') #plot DEM\n",
    "    ax.set_title(f'Locations on {volc} for kmeans group {aa}') #title\n",
    "    lons = locdf[locdf['kmeans_grp']==aa]['longitude'].values.tolist()\n",
    "    lats = locdf[locdf['kmeans_grp']==aa]['latitude'].values.tolist()\n",
    "    ax.scatter(lons,lats,marker='.',color='k',label='Cluster Locations') #plotting some points\n",
    "\n",
    "    ax.scatter(sta_lon,sta_lat,marker='o',color=\"white\",label=f\"station {sta.upper()}\")\n",
    "    ax.annotate(f'Station {sta}',xy=(sta_lon,sta_lat),xytext=(sta_lon,sta_lat-0.1),arrowprops=dict(color='white', headwidth=5, shrink=0.1, width=0.5), color='white',size=10)\n",
    "    \n",
    "    for point,name in zip([(i,ii) for i,ii in zip(lons,lats)], \\\n",
    "                          locdf[locdf['kmeans_grp']==aa]['cluster_id'].values.tolist()):\n",
    "        ax.annotate(name,xy=point,color='red',size=5)\n",
    "    \n",
    "    #crop/zoom-in on map\n",
    "    ax.set_xlim(left+0.3,right-0.4) #set manually to what looks best\n",
    "    ax.set_ylim(bottom+0.1,top-0.2) #set manually to what looks best\n",
    "fig.delaxes(ax0) #remove unused ax\n",
    "\n",
    "fig.savefig(f'/home/smocz/expand_redpy_new_files/cop_kmeans/tsne_normalized_{volc}_DEM_loc_{k}_{states}_states_labeled.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f8b43",
   "metadata": {},
   "source": [
    "### Time (Scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa56c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in new events (from eqcorrscan backfilling)\n",
    "\n",
    "#glob the event csvs (loop)\n",
    "pd_list = []\n",
    "for x in glob(f'{homedir}events/{volc}_*_events.csv'):\n",
    "    pd_list.append(pd.read_csv(x))\n",
    "#concat them into one csv\n",
    "nd_df = pd.concat(pd_list)\n",
    "#only have datetime and cluster id column\n",
    "nd_df = nd_df.drop('Stations_Found',axis='columns')\n",
    "nd_df = nd_df.drop('Stations',axis='columns')\n",
    "\n",
    "nd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb2181b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ncols = 1 #number of columns, stays consistent\n",
    "nrows = math.ceil(k/ncols) #determines number of rows needed by rounding up to nearest whole number\n",
    "\n",
    "fig, ax0 = plt.subplots(figsize=(ncols*10,nrows*5))\n",
    "gs = GridSpec(nrows, ncols, figure=fig) #make GridSpec for formatting subplots, based on ncols and nrows\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "for aa in range(0,k): #for each kmeans group\n",
    "    \n",
    "    ### find data for plotting ###\n",
    "    dt_list = [] #will be a list of all the dates (redpy and eqcorrscan)\n",
    "    r_dt_list = [] #list of just redpy dates\n",
    "    \n",
    "    cl_list = [cl[2:-1] for cl in cl_k_grp[cl_k_grp['kmeans_grp']==aa]['cluster_id'].values.tolist()] #list of cl in kmeans group\n",
    "    for cl in cl_list: #for each cluster in that group\n",
    "        d_list = [d[:10] for d in volc_ctlg[volc_ctlg['Clustered']==int(cl)]['datetime'].values.tolist()] #list of dates\n",
    "        nd_list = [d[:10] for d in nd_df[nd_df['Cluster_ID']==int(cl)]['Earliest_Detection_Time'].values.tolist()] #list of new dates\n",
    "        [dt_list.append(d) for d in d_list] #append to overall list\n",
    "        [r_dt_list.append(d) for d in d_list] #append to only redpy list\n",
    "        [dt_list.append(d) for d in nd_list] #append new dates (from eqcorrscan) to overall list\n",
    "    num_list = [dt_list.count(i) for i in np.unique(dt_list)] #count how many instances of a date appear in dt_list\n",
    "    r_num_list = [r_dt_list.count(i) for i in np.unique(r_dt_list)] #count instances of redpy detections\n",
    "    \n",
    "    df = pd.DataFrame({\"date\":np.unique(dt_list),\"number_events\":num_list})\n",
    "    r_df = pd.DataFrame({\"date\":np.unique(r_dt_list),\"number_events\":r_num_list})\n",
    "    \n",
    "    ### plot ###\n",
    "    ax = fig.add_subplot(gs[math.floor(aa/ncols):math.floor(aa/ncols)+1, \\\n",
    "            aa - math.floor(aa/ncols)*ncols:aa - math.floor(aa/ncols)*ncols +1]) #add subplot\n",
    "    x = pd.to_datetime([str(i) for i in df['date'].values.tolist()]) #read dates as string to pd datetime\n",
    "    y = df['number_events'].values.tolist() #number of events per day, same index as date list(x)\n",
    "    \n",
    "    ax.grid(which='major')\n",
    "    ax.grid(which='minor',color='#EEEEEE')\n",
    "\n",
    "#     ax.scatter(x,y,label='REDPy Events', color='red') #s=40,alpha=0.75,marker='.',\n",
    "    for xx,yy in zip(x,y):\n",
    "        plt.vlines(xx,ymin=0,ymax=yy, color='red')\n",
    "        \n",
    "    #plotting redpy values (no eqcorrscan detections)\n",
    "    x = pd.to_datetime([str(i) for i in r_df['date'].values.tolist()]) #read dates as string to pd datetime\n",
    "    y = r_df['number_events'].values.tolist() #number of events per day, same index as date list(x)\n",
    "    for xx,yy in zip(x,y):\n",
    "        plt.vlines(xx,ymin=0,ymax=yy, color='blue')\n",
    "\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Number of Events')\n",
    "    ax.set_yscale('log') #or 'linear'\n",
    "    ax.set_title(f'Number of Events Each Day on {volc} for k group {aa}')\n",
    "#     print(aa,len(dt_list))\n",
    "    \n",
    "fig.delaxes(ax0) #remove unused ax\n",
    "\n",
    "fig.savefig(f'/home/smocz/expand_redpy_new_files/cop_kmeans/tsne_normalized_{volc}_time_{k}_{states}_states.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee7854",
   "metadata": {},
   "source": [
    "### Waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fdcc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsta(t_name_byt): #get station from normalized template name\n",
    "    t_sta = str(t_name_byt)[2:-1].split('_')[1]\n",
    "    #t_net = str(t_name)[2:-1].split('_')[0] # can get net also\n",
    "    return t_sta #, t_net\n",
    "\n",
    "def getcl_id(t_name_str): #for normalized\n",
    "    t_cl = t_name_str.split('_')[-1]\n",
    "    return t_cl\n",
    "\n",
    "#for non-normalized\n",
    "# def getcl_id(t_name_str):\n",
    "#     t_cl = str(t_name_str)[-3:] #for zfill of 3\n",
    "#     return t_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e118a291",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get dataframe with template names (cluster) and waveform and kmeans group at one station\n",
    "templates = []\n",
    "waves = []\n",
    "for tname in template_name: #for each template name\n",
    "    t_sta = getsta(tname)\n",
    "    if t_sta.lower() == sta: \n",
    "#     if str(tname)[2:-1].startswith(sta): #use this for non-normalized template names\n",
    "        idx = list(template_name).index(tname)\n",
    "        t_wave = waveforms[idx]\n",
    "        templates.append(str(tname)[2:-1])\n",
    "        waves.append(t_wave)\n",
    "k_grps = []\n",
    "for t in templates:\n",
    "    #find which cluster it belongs to, and which kmeans group that belongs to\n",
    "    kn = cl_k_grp[cl_k_grp[\"cluster_id\"]==(f'b\\'{getcl_id(t).zfill(3)}\\'')][\"kmeans_grp\"].values.tolist()\n",
    "    k_grps.append(kn[0])\n",
    "wdf = pd.DataFrame({\"template_name\":list(templates),\"wave\":list(waves),\"kmeans\":k_grps})\n",
    "wdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6422318",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "from obspy import Trace\n",
    "\n",
    "print('number of clusters =',k)\n",
    "\n",
    "ax_list = np.arange(0,k,1) #list of groups, can do np.arange(0,n_clusters,1)\n",
    "\n",
    "ncols = k #number of columns, can be set manually\n",
    "nrows = math.ceil(k/ncols) #determines number of rows needed by rounding up to nearest whole number\n",
    "\n",
    "fig, ax0 = plt.subplots(figsize=(ncols*4,nrows*40))\n",
    "gs = GridSpec(nrows, ncols, figure=fig) #make GridSpec for formatting subplots, based on ncols and nrows\n",
    "fig.suptitle(f'Station {sta.upper()} Kmeans Grouping of REDPy Clusters',fontsize=16)\n",
    "# fig.set_tight_layout(True)\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.975])\n",
    "\n",
    "\n",
    "for aa,ax_n in enumerate(ax_list):#for each subplot\n",
    "#     print(f'----{ax_n}----')\n",
    "    ax = fig.add_subplot(gs[math.floor(aa/ncols):math.floor(aa/ncols)+1,aa - math.floor(aa/ncols)*ncols:aa - math.floor(aa/ncols)*ncols +1]) #add subplot\n",
    "    ax.set_title(f'Group Index {ax_n}') #label\n",
    "    \n",
    "    \n",
    "    wave_list = [Trace(i) for i in wdf[wdf['kmeans']==aa]['wave'].values.tolist()] #list of waveforms for a Kmeans group\n",
    "    name_list = [getcl_id(i) for i in wdf[wdf['kmeans']==aa]['template_name'].values.tolist()] #list of names for a Kmeans group\n",
    "\n",
    "    print(len(wave_list),'waveforms', end=', ')\n",
    "    \n",
    "    yscale = 2 #how far to space waveforms from eachother\n",
    "    wavecolor = 'black'\n",
    "    for ww, wave in enumerate(wave_list):\n",
    "        ax.plot(wave.data[:]/np.max(np.abs(wave.data))+yscale+(yscale*ww),color=wavecolor,linewidth=.5)\n",
    "        \n",
    "    for line, name in zip(ax.lines, name_list): #label each waveform with the cluster id\n",
    "        y = line.get_ydata()[-1] #find the y value where the line ends\n",
    "        ax.annotate(name, xy=(1,y), xytext=(6,0), color='red', \n",
    "                    xycoords = ax.get_yaxis_transform(), textcoords=\"offset points\",\n",
    "                    size=10, va=\"center\")\n",
    "    \n",
    "    x = np.arange(0,len(wave.data),1) #get np array of x points\n",
    "    xscale = 40 #samling rate in hz\n",
    "    ticks = ticker.FuncFormatter(lambda x, pos: '{0:g}'.format(x/xscale)) #set ticks in seconds instead of samples, 40 is sampling rate\n",
    "    ax.xaxis.set_major_formatter(ticks) #set ticks\n",
    "#     ax.set_xlabel('Time (s)')\n",
    "    \n",
    "    y = np.arange(1,len(wave_list),1) #get np array of y points\n",
    "    #yscale defined above\n",
    "    ticks = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y/yscale)) #set ticks in seconds instead of samples, 40 is sampling rate\n",
    "    ax.yaxis.set_major_formatter(ticks) #set ticks\n",
    "    ax.set_ylim(1,(len(wave_list)*yscale)+(.5*yscale))\n",
    "#     ax.set_ylabel('Number of Waveforms')\n",
    "    \n",
    "fig.delaxes(ax0) #remove unused ax\n",
    "fig.text(0.5, 0.0, 'Time (s)', ha='center')\n",
    "fig.text(0.0, 0.5, 'Number of Waveforms', va='center', rotation='vertical')\n",
    "\n",
    "print('showing plot...')\n",
    "\n",
    "fig.savefig(f'/home/smocz/expand_redpy_new_files/cop_kmeans/tsne_normalized_{volc}_waveforms_{k}_{states}_states.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f2e9f",
   "metadata": {},
   "source": [
    "### Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b023c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataframe with template names (cluster) and fingerprint and kmeans group at one station\n",
    "templates = []\n",
    "prints = []\n",
    "for tname in template_name: #for each template name\n",
    "    t_sta = getsta(tname)\n",
    "    if t_sta.lower() == sta: \n",
    "#     if str(tname)[2:-1].startswith(sta): #use this for non-normalized template names\n",
    "        idx = list(template_name).index(tname)\n",
    "        t_print = fingerprints[idx]\n",
    "        templates.append(str(tname)[2:-1])\n",
    "        prints.append(t_print)\n",
    "k_grps = []\n",
    "for t in templates:\n",
    "    #find which cluster it belongs to, and which kmeans group that belongs to\n",
    "    kn = cl_k_grp[cl_k_grp[\"cluster_id\"]==(f'b\\'{getcl_id(t).zfill(3)}\\'')][\"kmeans_grp\"].values.tolist()\n",
    "    k_grps.append(kn[0])\n",
    "fdf = pd.DataFrame({\"template_name\":list(templates),\"fingerprints\":list(prints),\"kmeans\":k_grps})\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053d226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for kn in np.arange(0,k,1): #for each k group\n",
    "    print_list = fdf[fdf['kmeans']==kn]['fingerprints'].values.tolist() #list of fingerprints for a Kmeans group\n",
    "    name_list = [getcl_id(i) for i in fdf[fdf['kmeans']==kn]['template_name'].values.tolist()] #list of names for a Kmeans group\n",
    "    \n",
    "    ncols=math.ceil(np.sqrt(len(print_list)))\n",
    "    nrows=math.ceil(len(print_list)/ncols)\n",
    "    print(f'{len(print_list)} fingerprints in {ncols} columns by {nrows} rows')\n",
    "    \n",
    "    del_list = [] #list of empty axes to delete\n",
    "    fig, axes = plt.subplots(nrows=nrows,ncols=ncols,figsize=(ncols*5,nrows*5))\n",
    "    for rr,row in enumerate(axes):\n",
    "        for aa,ax in enumerate(row):\n",
    "            idx = (ncols*rr)+aa\n",
    "            try:\n",
    "                ax.imshow(print_list[idx])\n",
    "                ax.set_title(f'fingerprint for cluster {name_list[idx]}')\n",
    "                ax.tick_params(axis='both', which='both', bottom=False,top=False,left=False,right=False,labelbottom=False,labelleft=False)\n",
    "            except:\n",
    "#                 print(f'axes {idx} is empty')\n",
    "                del_list.append(ax)\n",
    "    fig.suptitle(f'Fingerprints for kmeans group {kn} at Station {sta.upper()}',fontsize=25)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.975])\n",
    "    for i in del_list: #delete empty axes\n",
    "        fig.delaxes(i)\n",
    "    plt.show\n",
    "    fig.savefig(f'/home/smocz/expand_redpy_new_files/cop_kmeans/tsne_normalized_{volc}_{k}_grp{kn}_{sta.upper()}_prints_{states}_states.svg')\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c5262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo-py38-shared"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08930e2a",
   "metadata": {},
   "source": [
    "#  Sort Through Detections and Only Keep Certain Ones\n",
    "\n",
    "### Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0249ae1b",
   "metadata": {},
   "source": [
    "Import Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from glob import glob\n",
    "from obspy.signal.trigger import classic_sta_lta, plot_trigger, trigger_onset\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from obspy.core.utcdatetime import UTCDateTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a2447",
   "metadata": {},
   "source": [
    "Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aa0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = 13 #time in seconds after detection time\n",
    "# 13 because the templates are 13 seconds long, any longer and it could find the wrong signal\n",
    "tb = 10 #time in seconds before detection time\n",
    "# 10 because there needs to be 10 seconds of time before the signal for sta/lta to calibrate\n",
    "fs = 40 #sampling rate\n",
    "fqmin = 1 #minimum frequency for bandpass filter\n",
    "fqmax = 10 #maximum frequency for bandpass filter\n",
    "thr_on = 1.35 #threshold to turn the signal trigger on\n",
    "thr_off = 0.75 #threshold to turn the signal trigger off\n",
    "year = 2019 #year of detections to clean\n",
    "nsta = 5. #length of short window for signal detection in seconds\n",
    "nlta = 10. #length of long window for signal detection in seconds\n",
    "pr = 98 #percentile for SNR\n",
    "rpwi = 15 #time in seconds before and after REDpy catalog datetimes to exclude detections from, window length=2*rpwi\n",
    "homedir = '/home/smocz/redpy_expand_new_files/' #home directory or directory to save new files to\n",
    "datadir = '/data/wsd01/HOOD_data/UW/'+str(year)+'/' #directory to get data from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b0f83",
   "metadata": {},
   "source": [
    "Read the REDpy Catalogs and Volcano Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Baker = pd.read_csv('Baker_catalog.csv')\n",
    "Hood = pd.read_csv('Hood_catalog.csv')\n",
    "\n",
    "\n",
    "St_Helens = pd.read_csv('MountStHelens_catalog.csv')\n",
    "\n",
    "# Combining borehole and local catalogs with St_Helens\n",
    "\n",
    "Helens_Borehole = pd.read_csv('MSHborehole_catalog.csv')\n",
    "Helens_Borehole['Clustered'] += 2000 \n",
    "# Cluster 0 in Helens_Borehole is now Cluster 2000 in St_Helens\n",
    "Helens_Local = pd.read_csv('MSHlocal_catalog.csv')\n",
    "Helens_Local['Clustered'] += 3000\n",
    "# Cluster 0 in Helens_Local is now Cluster 3000 in St_Helens\n",
    "\n",
    "# Use St_Helens to access all three St Helens catalogs\n",
    "St_Helens = pd.concat([St_Helens,Helens_Borehole,Helens_Local])\n",
    "\n",
    "Newberry = pd.read_csv('Newberry_catalog.csv')\n",
    "Rainier = pd.read_csv('Rainier_catalog.csv')\n",
    "\n",
    "volc_md = pd.read_csv('Volcano_Metadata.csv')\n",
    "# read metadata file to create dataframe of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d58bdf1",
   "metadata": {},
   "source": [
    "Use Volcano Metadata to Create Lists of Stations for Each Volcano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33449666",
   "metadata": {},
   "outputs": [],
   "source": [
    "Baker_sta = volc_md[volc_md['Volcano_Name'] == 'Mt_Baker']['Station'].values.tolist()\n",
    "Hood_sta = volc_md[volc_md['Volcano_Name'] == 'Mt_Hood']['Station'].values.tolist() \n",
    "St_Helens_sta = volc_md[volc_md['Volcano_Name'] == 'Mt_St_Helens']['Station'].values.tolist()\n",
    "Newberry_sta = volc_md[volc_md['Volcano_Name'] == 'Newberry']['Station'].values.tolist() \n",
    "Rainier_sta = volc_md[volc_md['Volcano_Name'] == 'Mt_Rainier']['Station'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f81c80f",
   "metadata": {},
   "source": [
    "Create Lists of Volcano Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enumerate [0,1,2,3,4]\n",
    "volc_list = [Baker,Hood,Newberry,Rainier,St_Helens] # list of dataframes for each volcano\n",
    "volc_list_names = ['Baker','Hood','Newberry','Rainier','St_Helens'] # list of names of each volcano\n",
    "volc_sta = [Baker_sta,Hood_sta,Newberry_sta,Rainier_sta,St_Helens_sta] # lists of stations connected to respective volcanoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69e70c",
   "metadata": {},
   "source": [
    "### Sort Detections - Jul 28, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da04f3a",
   "metadata": {},
   "source": [
    "Updated 28, not tested yet - test on Hood 2019 detections from siletzia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make separate versions for each volcano\n",
    "# for vv,v in enumerate(volc_sta):\n",
    "v = Baker_sta\n",
    "vv = 0\n",
    "for s in range(0,len(v)): \n",
    "    try:\n",
    "        read = pd.read_csv(homedir+'detections/'+volc_list_names[vv]+'_'+v[s]+'_'+year+'_detections.csv')\n",
    "    except:\n",
    "        print('No detections for',v[s])\n",
    "        continue\n",
    "        \n",
    "    with open(homedir+'detections/'+volc_list_names[vv]+'_'+v[s]+'_'+str(year)+\n",
    "          '_clean_detections.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Template_Name\",\"Detection_Time\", \"Trigger_on\", \"Trigger_off\",\"SNR\"])\n",
    "        file.close()\n",
    "        \n",
    "    #Make list of all clusters that have a template\n",
    "    temp_name_list = read['Template_Name'].values.tolist() #make a list of template names\n",
    "    cl_list_long = [] # make a list of the numbers in each template name, like [0,6,8,0,0,2,6,6,6,8,8...6]\n",
    "    for i in temp_name_list: \n",
    "        num = re.findall(r'\\d+', i)\n",
    "        cl_list_long.append(*num)\n",
    "    cl_list = np.unique(cl_list_long) #get rid of duplicates, like [0,6,8,2]\n",
    "#     cl_list = [int(i) for i in cl_list] #change str to int\n",
    "#     cl_list.sort() #put it in order from least to greatest, like [0,2,6,8]\n",
    "\n",
    "    #find the channel as it appears in template names\n",
    "#     chan_list = list(temp_name_list[0]) #get a template name\n",
    "#     chan_list1 = []\n",
    "#     for i in chan_list: #make a list of characters, exclude numbers, of template name\n",
    "#         num = re.findall(r'\\d+', i)\n",
    "#         if num: continue\n",
    "#         chan_list1.append(i)\n",
    "#     chan_ = ''.join(chan_list1[-7:-4]) #make a string of the 7th to 4th from last characters (the channel)\n",
    "\n",
    "    for cl in cl_list:\n",
    "        times = [] #list of datetimes for this cluster\n",
    "        for i in np.unique(temp_name_list):\n",
    "            if i.endswith(cl):\n",
    "                all_times = readsta[readsta['Template_Name']==i]['Detection_Time'].values.tolist()\n",
    "                for at in all_times:\n",
    "                    times.append(at)\n",
    "#         times = read[read['Template_Name'] == v[s].lower()+chan_+'rpho'+str(cl)]['Detection_Time'].values.tolist()\n",
    "        for ii,i in enumerate(times):\n",
    "            et=UTCDateTime(i)+ta\n",
    "            stt=UTCDateTime(i)-tb\n",
    "            utct=UTCDateTime(i)\n",
    "            st = obspy.read(*glob(datadir+str(i.julday).zfill(3)+'/'+v[s]+'.*.'+str(year)+'.*'))\n",
    "            st.select(component=\"Z\") #Use only the Z Component\n",
    "            st.filter(type='bandpass',freqmin=fqmin,freqmax=fqmax)\n",
    "            st.detrend(type='demean')\n",
    "            st.resample(fs)\n",
    "            st.trim(starttime=stt,endtime=et)\n",
    "            st.merge(fill_value = 0)\n",
    "            if len(st)==0: continue\n",
    "    # classic\n",
    "            try:\n",
    "                cft = classic_sta_lta(st[0].data, int(nsta * fs), int(nlta * fs))\n",
    "                print('-------------')\n",
    "                print('detection: '+str(ii),'cluster id: '+str(cl))\n",
    "                plot_trigger(st[0], cft, thr_on, thr_off)\n",
    "                on_off = np.array(trigger_onset(cft, thr_on, thr_off))\n",
    "                # show trigger on and off times, rounded to 4 decimal places\n",
    "                trig_on = round(float(on_off[:, 0] / fs)-tb,4)\n",
    "                trig_off = round(float(on_off[:, 1] / fs)-tb,4)\n",
    "                print('Trigger on',trig_on,'seconds after detect time')\n",
    "                print('Trigger off',trig_off,'seconds after detect time')\n",
    "            except:\n",
    "                print('NOT FOUND') #if no signal can be found, print 'NOT FOUND' and skip the rest of the loop\n",
    "                continue\n",
    "            signal_window = st[0].copy()\n",
    "            noise_window = st[0].copy()\n",
    "\n",
    "            signal_window.trim(starttime=UTCDateTime(i)+trig_on-0.5,endtime=UTCDateTime(i)+trig_off) \n",
    "            #i+trig_on-0.5 to include lead up to the signal\n",
    "            noise_window.trim(starttime=UTCDateTime(i)-10,endtime=UTCDateTime(i))\n",
    "\n",
    "            snr = 20 * np.log(np.percentile(np.abs(signal_window.data),pr) \n",
    "                              / np.percentile(np.abs(noise_window.data),pr))/np.log(10)\n",
    "            if snr<7.: continue #if SNR is too low, skip saving it\n",
    "\n",
    "            #put skipping REDpy detections here\n",
    "            #read REDpy catalog to have a reference\n",
    "            catalog = pd.read_csv('Hood_catalog.csv')\n",
    "            rpdatetimes = catalog[catalog['Clustered'] == cl]['datetime'].values.tolist() \n",
    "            #make a list of datetimes for the current cluster\n",
    "            skip=1 #set variable to arbitrary number\n",
    "            for rr,r in enumerate(rpdatetimes):\n",
    "                rs = UTCDateTime(r)-rpwi\n",
    "                rend = UTCDateTime(r)+rpwi #changed from re to rend because of import re for cl_list\n",
    "                if UTCDateTime(i)>rs and UTCDateTime(i)<rend:\n",
    "                    skip=2 #if there is an overlap, reset the variable and break out of the loop\n",
    "                    print('Overlap with REDpy detections')\n",
    "                    break\n",
    "            if skip!=2: #if skip has NOT been redefined, save this detection\n",
    "                for u in np.unique(temp_name_list):\n",
    "                    if u.endswith(cl):\n",
    "                        t = u\n",
    "                row = [t,i,trig_on,trig_off,snr]\n",
    "                print(row)\n",
    "    #             automatically filters out detections that it can't find a signal for\n",
    "                with open(homedir+'detections/'+volc_list_names[vv]+'_'+v[s]+'_'+str(year)+\n",
    "                          '_clean_detections.csv', 'a', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(row)\n",
    "                    file.close()\n",
    "\n",
    "\n",
    "            break\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

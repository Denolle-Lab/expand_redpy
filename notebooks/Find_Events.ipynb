{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab72beec",
   "metadata": {},
   "source": [
    "Import Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55331a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "import obspy\n",
    "from obspy import UTCDateTime\n",
    "from time import time\n",
    "import csv\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a75a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/smocz/expand_redpy/scripts/config.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "vv = config['vv']\n",
    "volc_list = ['Baker','Hood','Newberry','Rainier','St_Helens']\n",
    "volc = volc_list[vv]\n",
    "year = config['year']\n",
    "\n",
    "homedir = config['homedir']\n",
    "readdir = config['readdir']\n",
    "\n",
    "#time in seconds before and after a detection to check for similar detections\n",
    "wi = config['wi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03db1b6",
   "metadata": {},
   "source": [
    "Parameters and dataframes for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386de310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get volcano metadata\n",
    "df = pd.read_csv(readdir+'Volcano_Metadata.csv')\n",
    "#station list\n",
    "sta_list = df[df['Volcano_Name']==volc]['Station'].values.tolist() #CHANGE MT_BAKER TO VOLC\n",
    "#panda dataframe for detections at a station\n",
    "readstadict = {}\n",
    "for i in sta_list:\n",
    "    readstadict[i] = pd.read_csv(homedir+'detections/'+volc+'_'+i+'_'+str(year)+'_clean_detections.csv') \n",
    "rsta_list = []\n",
    "for i in readstadict:\n",
    "    rsta_list.append(readstadict[i])\n",
    "readsta = pd.concat(rsta_list)\n",
    "print(sta_list)\n",
    "print(type(rsta_list[0]))\n",
    "print(rsta_list)\n",
    "print(readsta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a18d50",
   "metadata": {},
   "source": [
    "# NOTE FOR EDITING: be sure to also update below cell when adding stations\n",
    "### new loop per station, update sta#times and readsta#, update match#, and add match# to match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "with open(homedir+'events/'+volc+'_'+year+'_events.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Earliest_Detection_Time\",\"Cluster_ID\",\"Stations_Found\",\"Stations\"])\n",
    "    #detection time, cluster id (no longer needs to be separated by station), and number of stations with a \n",
    "    #detection for this event\n",
    "    file.close()\n",
    "\n",
    "#for all detections we want to run (concatenated)\n",
    "temp_name_list = readsta['Template_Name'].values.tolist() #make a list of template names\n",
    "cl_list_long = [] # make a list of the numbers in each template name\n",
    "for i in temp_name_list: \n",
    "    num = re.findall(r'\\d+', i)\n",
    "    cl_list_long.append(*num)\n",
    "cl_list = np.unique(cl_list_long) #get rid of duplicates\n",
    "\n",
    "#for cluster x\n",
    "for cl in cl_list:\n",
    "    t1 = time()\n",
    "#for detection x\n",
    "    times = []\n",
    "    for i in np.unique(temp_name_list):\n",
    "        if i.endswith(cl):\n",
    "            all_times = readsta[readsta['Template_Name']==i]['Detection_Time'].values.tolist()\n",
    "            for at in all_times:\n",
    "                times.append(at)\n",
    "    for ii,i in enumerate(times):\n",
    "        t3 = time()\n",
    "#run through each detection time on all stations\n",
    "        print( )\n",
    "        print('------------')\n",
    "        print('trying detection',ii,'cluster',cl,i)\n",
    "        \n",
    "        match_list = []\n",
    "        for ss,s in enumerate(sta_list):\n",
    "            statimes = []\n",
    "            for a in np.unique(readstadict[s]['Template_Name'].values.tolist()):\n",
    "                if a.endswith(cl):\n",
    "                    all_times = readstadict[s][readstadict[s]['Template_Name']==a]['Detection_Time'].values.tolist()\n",
    "                    for at in all_times:\n",
    "                        statimes.append(at)\n",
    "            match=0 #set variable to arbitrary number\n",
    "            for tt,t in enumerate(statimes):\n",
    "                ts = UTCDateTime(t)-wi\n",
    "                te = UTCDateTime(t)+wi\n",
    "                if UTCDateTime(i)>ts and UTCDateTime(i)<te:\n",
    "                    match=2 #if there is an overlap, reset the variable and break out of the loop\n",
    "                    print('Overlap with station '+s+' detections')\n",
    "                match_list.append(match)\n",
    "        print('match_list:',match_list)\n",
    "        \n",
    "        t2 = time()\n",
    "        print(t2-t3,'seconds to test overlap for detection',ii)\n",
    "    \n",
    "        save_list = [] #for saving a list of stations\n",
    "        for mm,m in enumerate(match_list):\n",
    "            if m==2:\n",
    "                save_list.append(sta_list[mm])\n",
    "\n",
    "        if match_list.count(2) >= 4: #if at least 4 matches equal 2:\n",
    "#         if match==2 and match0==2 and match1==2 and match2==2:\n",
    "            print('saving...')\n",
    "            #ADD A CATCH: if an event of this cluster and this time give or take 1 second \n",
    "            #already exists, do NOT save\n",
    "            check = pd.read_csv(homedir+'events/'+volc+'_'+str(year)+'_events.csv')\n",
    "            checktimes = check[check['Cluster_ID']==int(cl)]['Detection_Time'].values.tolist()\n",
    "            checking = 0\n",
    "            for tt,t in enumerate(checktimes):\n",
    "                ts = UTCDateTime(t)-wi\n",
    "                te = UTCDateTime(t)+wi\n",
    "                if UTCDateTime(i)>ts and UTCDateTime(i)<te: \n",
    "                    print('already recorded event')\n",
    "                    checking=1 #checking still =1 because we don't want the normal save process\n",
    "                    #if i is earlier (less than) than the recorded event, overwrite the event (we want the earliest detected time)\n",
    "                    if i<t:\n",
    "                        print('replacing...')\n",
    "                        print('old time:',t,'new time:',i)\n",
    "                        check.replace(t,i,inplace=True) #ONLY WORKS FOR THE DATAFRAME NOT THE CSV\n",
    "                        check.to_csv(homedir+'events/'+volc+'_'+year+'_events.csv',index=False)\n",
    "                        #read panda dataframe - change dataframe, overwrite the csv with this dataframe\n",
    "                        print('changed csv')\n",
    "                        #2+ clusters at the same time shouldn't happen because templates are 13s long, with \n",
    "                        #trig int of 6. any '2' events in the same window would just be one event and waves \n",
    "                        #shouldn't be so slow that a different one can be at the exact time (within 1 second \n",
    "                        #of the detection)\n",
    "                    break\n",
    "            if checking==1: continue\n",
    "            row = [i,int(cl),match_list.count(2),' '.join(save_list)]\n",
    "            print(row)\n",
    "            \n",
    "            with open(homedir+'events/'+volc+'_'+year+'_events.csv', 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(row)\n",
    "                file.close()\n",
    "    t4 = time()\n",
    "    print(t4-t3,'seconds for cluster',cl)\n",
    "t5 = time()\n",
    "print(t5-t0,'seconds to find all new events on',volc,'in',year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212ee5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

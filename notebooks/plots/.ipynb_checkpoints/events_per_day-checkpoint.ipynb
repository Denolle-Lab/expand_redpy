{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2a3b36",
   "metadata": {},
   "source": [
    "Getting into events per day format in a csv. Set up for Mt St Helens - created December 2022\n",
    "\n",
    "additional event plots (clusters with new events, years with new events, etc.) below - created May 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f242e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/smocz/expand_redpy/scripts/config.yaml') as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "vv = config['vv']\n",
    "volc_list_names = config['volc_list_names']\n",
    "volc = volc_list_names[vv]\n",
    "readdir = config['readdir']\n",
    "homedir = config['homedir']\n",
    "years = config['years']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724249d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4281eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the St_Helens csvs\n",
    "\n",
    "St_Helens = pd.read_csv(readdir+'MountStHelens_catalog.csv')\n",
    "\n",
    "# Combining borehole and local catalogs with St_Helens\n",
    "\n",
    "Helens_Borehole = pd.read_csv(readdir+'MSHborehole_catalog.csv')\n",
    "Helens_Borehole['Clustered'] += 2000 \n",
    "# Cluster 0 in Helens_Borehole is now Cluster 2000 in St_Helens\n",
    "Helens_Local = pd.read_csv(readdir+'MSHlocal_catalog.csv')\n",
    "Helens_Local['Clustered'] += 3000\n",
    "# Cluster 0 in Helens_Local is now Cluster 3000 in St_Helens\n",
    "\n",
    "# Use St_Helens to access all three St Helens catalogs\n",
    "St_Helens = pd.concat([St_Helens,Helens_Borehole,Helens_Local])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ac31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read Hood csv\n",
    "Hood = pd.read_csv(readdir+'Hood_catalog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b0dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make events_per_day csv\n",
    "\n",
    "###################\n",
    "# SET UP FOR HOOD #\n",
    "###################\n",
    "\n",
    "dt_list = Hood['datetime'].values.tolist() #get a list of datetimes\n",
    "\n",
    "d_list = [] #get list of dates\n",
    "for dt in dt_list:\n",
    "    d = dt[:10] #take the date out of the datetime\n",
    "    d_list.append(d) #append to list\n",
    "\n",
    "uni_d_list = np.unique(d_list)\n",
    "\n",
    "num_list = [] #list of number of events on that date, index is the same as uni_d_list\n",
    "for i in uni_d_list:\n",
    "    num = d_list.count(i)\n",
    "    num_list.append(num)\n",
    "\n",
    "df = pd.DataFrame(list(zip(uni_d_list,num_list)))\n",
    "df.columns = ['Date','Number_of_Events']\n",
    "print(df)\n",
    "\n",
    "# df.to_csv(homedir+'Mt_Hood_events_per_day.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e6c01",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read pnsn dates FOR HOOD\n",
    "pnsn = pd.read_csv(homedir+'pnsn_Hood.csv')\n",
    "\n",
    "dt_list = pnsn['Time UTC'].values.tolist() #get a list of datetimes\n",
    "\n",
    "d_list = [] #get list of dates\n",
    "for dt in dt_list:\n",
    "    d = dt[:10] #take the date out of the datetime\n",
    "    d_list.append(d) #append to list\n",
    "\n",
    "uni_d_list = np.unique(d_list)\n",
    "\n",
    "num_list = [] #list of number of events on that date, index is the same as uni_d_list\n",
    "for i in uni_d_list:\n",
    "    num = d_list.count(i)\n",
    "    num_list.append(num)\n",
    "\n",
    "pnsn_df = pd.DataFrame(list(zip(uni_d_list,num_list)))\n",
    "pnsn_df.columns = ['Date','Number_of_Events']\n",
    "print(pnsn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read new events (from backfilling)\n",
    "\n",
    "new_e = pd.read_csv('/home/smocz/expand_redpy_new_files/final_catalogs/Hood_updated_catalog.csv')\n",
    "\n",
    "dt_list =  new_e['Earliest_Detection_Time'].values.tolist() #get a list of datetimes\n",
    "\n",
    "d_list = [] #get list of dates\n",
    "for dt in dt_list:\n",
    "    d = dt[:10] #take the date out of the datetime\n",
    "    d_list.append(d) #append to list\n",
    "\n",
    "uni_d_list = np.unique(d_list)\n",
    "\n",
    "num_list = [] #list of number of events on that date, index is the same as uni_d_list\n",
    "for i in uni_d_list:\n",
    "    num = d_list.count(i)\n",
    "    num_list.append(num)\n",
    "\n",
    "new_df = pd.DataFrame(list(zip(uni_d_list,num_list)))\n",
    "new_df.columns = ['Date','Number_of_Events']\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8850f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#font\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(homedir+'Mt_Hood_events_per_day.csv')\n",
    "#for REDPy\n",
    "x = df['Date'].values.tolist() #read date values\n",
    "str_x = [str(i) for i in x] #make sure they are all strings\n",
    "x = pd.to_datetime(str_x) #change to datetime for plotting\n",
    "\n",
    "y = df['Number_of_Events'].values.tolist() #number of events per day, same index as date list(x)\n",
    "\n",
    "#for PNSN\n",
    "px = pnsn_df['Date'].values.tolist()\n",
    "str_px = [str(i) for i in px]\n",
    "px = pd.to_datetime(str_px)\n",
    "\n",
    "py = pnsn_df['Number_of_Events'].values.tolist()\n",
    "\n",
    "#for NEW\n",
    "nx = new_df['Date'].values.tolist()\n",
    "str_nx = [str(i) for i in nx]\n",
    "nx = pd.to_datetime(str_nx)\n",
    "\n",
    "ny = new_df['Number_of_Events'].values.tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,7.5))\n",
    "\n",
    "ax.grid(which='major')\n",
    "ax.grid(which='minor',color='#EEEEEE')\n",
    "\n",
    "ax.scatter(px,py,s=40,alpha=0.75,marker='.',label='PNSN Events', color='purple') \n",
    "ax.scatter(x,y,s=40,alpha=0.75,marker='.',label='REDPy Events', color='red')\n",
    "ax.scatter(nx,ny,s=40,marker='.',label='Backfilled Events',color='black') \n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Number of Events')\n",
    "ax.set_yscale('log')\n",
    "ax.set_title('Number of Events Each Day on Mt Hood')\n",
    "plt.legend(loc='upper center')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d35471c",
   "metadata": {},
   "source": [
    "Additional event analysis plots - May 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new events per year\n",
    "\n",
    "#clusters of new events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc89a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# INCLUDES REDPY OVERLAP #\n",
    "##########################\n",
    "\n",
    "\n",
    "##read in event csvs for volcano selected in config.yaml\n",
    "# event_csvs = glob(f'{homedir}events/{volc_list_names[vv]}_*_events.csv')\n",
    "# print(event_csvs[0])\n",
    "\n",
    "# event_dfs = []\n",
    "# for csv in event_csvs:\n",
    "#     event_dfs.append(pd.read_csv(csv))\n",
    "    \n",
    "# event_df = pd.concat(event_dfs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# EXCLUDES REDPY OVERLAP #\n",
    "##########################\n",
    "\n",
    "event_df = pd.read_csv(homedir+f'final_catalogs/{volc_list_names[vv]}_updated_catalog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a746919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show df\n",
    "event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2cb898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get info\n",
    "\n",
    "#count of cl\n",
    "cl_unique = list(np.unique(event_df[\"Cluster_ID\"])) #ordered, non-repeating list of cluster IDs\n",
    "cl_count = [] #number of instances of each cluster ID, same index as cl_unique\n",
    "for cl in cl_unique:\n",
    "    cl_count.append(list(event_df[\"Cluster_ID\"]).count(cl))\n",
    "    \n",
    "#get count of events per year\n",
    "year_list = [pd.to_datetime(i).year for i in event_df[\"Earliest_Detection_Time\"]]\n",
    "year_unique = np.unique(year_list) #ordered, non-repeating list of years with at least one detection\n",
    "year_count = [] #how many detections in each year, same index as year_list\n",
    "for yy in year_unique:\n",
    "    year_count.append(year_list.count(yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot cluster count as bar chart\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for ii, i in enumerate(cl_unique):\n",
    "    ax.vlines(i,0,cl_count[ii], lw=2)\n",
    "ax.set_xlabel('Cluster ID')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title(f'{volc_list_names[vv]} New Events by Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f08d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot cluster count as pie chart\n",
    "\n",
    "plot_cl_unique = []\n",
    "plot_cl_count = []\n",
    "#pick out clusters with more than so many events\n",
    "for ii, i in enumerate(cl_unique):\n",
    "    if cl_count[ii] > 5:\n",
    "        plot_cl_unique.append(i)\n",
    "        plot_cl_count.append(cl_count[ii])\n",
    "        \n",
    "count_percent = [i/sum(plot_cl_count) for i in plot_cl_count]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(count_percent, labels=plot_cl_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot year count\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for ii, i in enumerate(year_unique):\n",
    "    ax.vlines(i,0,year_count[ii],lw=8)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title(f'{volc_list_names[vv]} New Events per Year (2002-2021)')\n",
    "ax.set_xticks([2000,2002,2004,2006,2008,2010,2012,2014,2016,2018,2020,2022])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2aee0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo 3.8 (SHARED)",
   "language": "python",
   "name": "seismo-py38-shared"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
